---
title: "Ghana Air Quality Analysis"
output: 
  html_document:
    toc: true
    theme: united
date: "2024-06-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
### load packages 
library(here) 
library(lubridate) 
library(tictoc)
library(DT)
library(purrr)
library(tidyverse)
library(data.table)
library(sf)
library(viridis)
library(knitr)
library(modelsummary)
library(spdep)
library(gstat)
library(units) 
library(gridExtra)

library(broom)
library(Metrics)
library(kableExtra)

```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Source in functions

# source in function that loads each pollution dataset separately to keep data small and prevent R crashes 
source(here("src", "load_pollution_datasets.R"))

# source function that aggregates data by time scale of interest (hourly, daily)
source(here("src", "summarize_pollution_times.R"))

# Source function that creates fleet average vs monitor pollutant reading plot
source(here("src", "compare_fleet_avg_monitor.R"))

# Source function that creates heatmap of pollutant readings
source(here("src", "generate_heatmap.R"))

# Source function to make map of pollution values at each monitor location
source(here("src", "generate_spatial_pollution_map.R"))

# source function to calculate moran i 
source(here("src", "calculate_moran_i.R"))

# source function to prepare data for road regression analysis and plotting
source(here("src", "prep_monitor_road_data.R"))

# source function to plot map of pollutant levels by location with roads 
source(here("src", "generate_spatial_pollution_road_map.R"))

# source function to run regression analysis on pollutant / distance to road
source(here("src", "regress_pollutant_road.R"))

# source function to apply regressions when comparing monitor to fleet average
source(here("src", "compare_fleet_regression.R"))

# source functions to merge in the SD card data for cases when server data is missing 
source(here("src", "merge_sd_data.R"))
source(here("src", "process_multiple_pollutants.R"))


```


```{r location data, echo=FALSE, message=FALSE, warning=FALSE}
#LOAD LOCATION DATA ----

# identify the location columns
location_columns <- c("monitor", "geo_lat", "geo_lon", "date")

# read in the monitor location data using fread to handle large dataset
location_data <- fread("/Users/lewiswhite/CHAP_columbia/QuantAQ/ghana_AQ_parent_full.csv", 
                       select = location_columns, 
                       showProgress = TRUE)

# remove missing values and filter to recent monitor locations 
location_complete <- location_data[complete.cases(location_data$geo_lat, location_data$geo_lon), ] %>%
  filter(date > as.Date("2024-03-01"))

# Get unique combinations for each device
monitor_locations <- location_complete %>%
  group_by(monitor) %>%
  distinct(geo_lat, geo_lon) %>%
  
  # ADJUSTMENTS (ASK DJ TO CONFIRM) DUE TO ERRORS IN LONGITUDE
  mutate(geo_lon = case_when(geo_lon == -173058.0000 ~ -1.73058,
                             geo_lon == 1.5990 ~ -1.5990,
                             TRUE ~ geo_lon)) %>%
  filter(geo_lat != 8.05630)

# create spatial feature dataset of monitor points
monitor_points <- st_as_sf(monitor_locations, coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))



# LOAD IN THE COUNTRY AND REGION MAP DATA ----

country <- st_read(here("gha_admbnda_gss_20210308_SHP", "gha_admbnda_adm0_gss_20210308.shp"), quiet = TRUE)

regions <- st_read(here("gha_admbnda_gss_20210308_SHP", "gha_admbnda_adm1_gss_20210308.shp"), quiet = TRUE) %>%
  rename(region = ADM1_EN)

bono_east <- regions %>% filter(region == "Bono East")

# just the lat/lon for kintampo
kintampo_sf <- st_as_sf(data.frame(
  location = "Kintampo",
  geo_lon = -1.7296,
  geo_lat = 8.0593
), coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))


# LOAD IN THE ROADS DATA ----

# Load roads data and set CRS (assuming it's EPSG:4326)
roads <- st_read(here("hotosm_gha_roads_lines_shp", "hotosm_gha_roads_lines_shp.shp"), quiet = TRUE)
st_crs(roads) <- 4326


# Define the bounding box
bounding_box <- st_bbox(c(xmin = -2.2, ymin = 7.6, xmax = -1.3, ymax = 8.8), crs = st_crs(4326))

# Create a bounding box as an sf object
bbox_sf <- st_as_sfc(bounding_box)

# Filter the roads dataset to include only those within the bounding box
roads_filtered <- st_intersection(roads, bbox_sf)
```

```{r pm1 data, echo=FALSE, message=FALSE, warning=FALSE}
# LOAD POLLUTION DATA ----

# Define the pollutants of interest
pollutants <- c("pm1", "pm10", "pm25")

# Define the list to store results
results <- list()

# Load and summarize the data for each pollutant
for (pollutant in pollutants) {
  load_pollution_datasets(pollutant)
  
  colocation_data <- get(paste0(pollutant, "_colocation"))
  community_data <- get(paste0(pollutant, "_community"))
  
  colocation_summary <- summarize_pollution_times(colocation_data, pollutant)
  community_summary <- summarize_pollution_times(community_data, pollutant)
  
  results[[paste0(pollutant, "_colocation_hourly")]] <- colocation_summary$hourly
  results[[paste0(pollutant, "_colocation_daily")]] <- colocation_summary$daily
  results[[paste0(pollutant, "_community_hourly")]] <- community_summary$hourly
  results[[paste0(pollutant, "_community_daily")]] <- community_summary$daily
}

# Access the summarized results
pm1_colocation_hourly <- results$pm1_colocation_hourly
pm1_colocation_daily <- results$pm1_colocation_daily
pm10_colocation_hourly <- results$pm10_colocation_hourly
pm10_colocation_daily <- results$pm10_colocation_daily
pm25_colocation_hourly <- results$pm25_colocation_hourly
pm25_colocation_daily <- results$pm25_colocation_daily
pm1_community_hourly <- results$pm1_community_hourly
pm1_community_daily <- results$pm1_community_daily
pm10_community_hourly <- results$pm10_community_hourly
pm10_community_daily <- results$pm10_community_daily
pm25_community_hourly <- results$pm25_community_hourly
pm25_community_daily <- results$pm25_community_daily



# LOAD IN THE GAS DATA ----

# Define the pollutants of interest
gasses <- c("co", "no", "no2", "o3")

# Define the list to store results
results <- list()

# Load and summarize the data for each gas
for (gas in gasses) {
  cat("Loading data for:", gas, "\n")
  load_pollution_datasets(gas) 
  
  colocation_data_name <- paste0(gas, "_colocation")
  community_data_name <- paste0(gas, "_community")
  
  if (exists(colocation_data_name) && exists(community_data_name)) {
    colocation_data <- get(colocation_data_name)
    community_data <- get(community_data_name)
    
    colocation_summary <- summarize_pollution_times(colocation_data, gas)
    community_summary <- summarize_pollution_times(community_data, gas)
    
    results[[paste0(gas, "_colocation_hourly")]] <- colocation_summary$hourly
    results[[paste0(gas, "_colocation_daily")]] <- colocation_summary$daily
    results[[paste0(gas, "_community_hourly")]] <- community_summary$hourly
    results[[paste0(gas, "_community_daily")]] <- community_summary$daily
  } else {
    warning(paste("Data for", gas, "not found."))
  }
}



co_colocation_hourly <- results$co_colocation_hourly %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

co_colocation_daily <- results$co_colocation_daily %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

co_community_hourly <- results$co_community_hourly %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

co_community_daily <- results$co_community_daily %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)


no_colocation_hourly <- results$no_colocation_hourly %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

no_colocation_daily <- results$no_colocation_daily %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

no_community_hourly <- results$no_community_hourly %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

no_community_daily <- results$no_community_daily %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

no2_colocation_hourly <- results$no2_colocation_hourly %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

no2_colocation_daily <- results$no2_colocation_daily %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

no2_community_hourly <- results$no2_community_hourly %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

no2_community_daily <- results$no2_community_daily %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)


o3_colocation_hourly <- results$o3_colocation_hourly %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

o3_colocation_daily <- results$o3_colocation_daily %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

o3_community_hourly <- results$o3_community_hourly %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)

o3_community_daily <- results$o3_community_daily %>% 
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>% 
  filter(mod_pm == FALSE) %>%
  select(-mod_pm)
```


## Monitor Locations

```{r monitor locations, echo=FALSE, message=FALSE, warning=FALSE}
# Define the bounding box coordinates
bbox_coords <- matrix(c(-2.2, 7.6, -2.2, 8.8, -1.3, 8.8, -1.3, 7.6, -2.2, 7.6), ncol = 2, byrow = TRUE)
bbox_polygon <- st_polygon(list(bbox_coords))
bbox_sf <- st_sfc(bbox_polygon, crs = st_crs(4326))

# Plot the map with the bounding box
ggplot() +
  # Add Ghana regions
  geom_sf(data = regions, fill = ifelse(regions$region == "Bono East", "#f5e493", "lightblue"), color = "black", alpha = 0.5) +
  # Add monitor points with transparency
  geom_sf(data = monitor_points, aes(geometry = geometry), color = "red", alpha = 0.5, size = 2) +
  # Add bounding box
  geom_sf(data = bbox_sf, fill = NA, color = "blue", lwd = 0.5, linetype = "solid") +
  # Add Ghana country boundary
  geom_sf(data = country, fill = NA, color = "black", size = 1) +
  labs(title = "Monitor Locations in Ghana") +
  theme_bw()


# Plot the zoomed-in map
ggplot() +
  # Add Ghana regions within the bounding box
  geom_sf(data = regions, fill = ifelse(regions$region == "Bono East", "#f5e493", "lightblue"), color = "black", alpha = 0.5) +
  # Add monitor points with transparency within the bounding box
  geom_sf(data = monitor_points, aes(geometry = geometry), color = "red", alpha = 0.5, size = 5) +
  # Add Kintampo marker
  geom_sf(data = kintampo_sf, aes(geometry = geometry), shape = 20, size = 3, color = "black") +
  # Add annotation text
  annotate("text", x = -1.73, y = 8.09, label = "KHRC", color = "black", size = 5) +
  # Zoom in to the bounding box
  coord_sf(xlim = c(-2.2, -1.3), ylim = c(7.6, 8.8), expand = FALSE) +
  labs(title = "Monitor Locations (Zoomed-In)",
       x = "", 
       y = "") +
  theme_bw()
```


# Summarizing Missingness

## Colocation Missingness

```{r colocation missingness, echo=FALSE, message=FALSE, warning=FALSE}
# THE MISSING DATA APPEARS TO BE CONSISTENT ACCROSS POLLUTANTS, SO USING PM 1 TO IDENTIFY MISSING VALUES 

# calculate total missingness across all of the monitors and the entire time range of interest 
overall_missingness <- mean(is.na(pm1_colocation$pm1)) * 100

# daily missingness  
daily_missingness <- pm1_colocation %>% 
  group_by(date) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  
  filter(date > as.Date("2023-08-15") & date < as.Date("2023-09-21"))

# hourly missingingness
hourly_missingness <- pm1_colocation %>% 
  group_by(hour) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100)

#monitor missingness
monitor_missingness <- pm1_colocation %>% 
  group_by(monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  mutate(monitor = fct_reorder(monitor, -missing_rate))



## DAILY MISSING DATA PERCENTAGE ----

#aggregated across monitors 
ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  geom_line() +
  labs(title = "Daily Missing Data Rate Over Time During Monitor Colocation", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")

#aggregated across monitors, smoothed
ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  stat_smooth(span = 0.5) +
  labs(title = "Daily Missing Data Rate Over Time During Monitor Colocation", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")

  


## TOTAL MISSING DATA FOR EACH MONITOR ----

ggplot(monitor_missingness, aes(x = monitor, y = missing_rate)) +
  geom_bar(stat = "identity") +
  labs(title = "Missing Data Rate by Monitor During Colocation", x = "Monitor", y = "Missing Data Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 


# MISSING DATA PERCENTAGE FOR EACH HOUR OF THE DAY

#aggregated by monitor 
ggplot(hourly_missingness, aes(x = hour, y = missing_rate)) +
  geom_line() +
  labs(title = "Hourly Missing Data Rate During Monitor Colocation", x = "Hour of the Day", y = "Missing Data Rate (%)") +
  theme_minimal()

#facet wrap for each monitor 
pm1_colocation %>% 
  group_by(hour, monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  ggplot(aes(x = hour, y = missing_rate)) +
  geom_line() +
  facet_wrap(~monitor) +
  labs(y = "Missing data rate (%)",
       x = "Hour of the Day",
       title = "Hourly Missing Data Rate for Each Monitor During Colocation") +
  theme_bw()



## HEATMAP OF MISSINGNESS PER DAY FOR EACH MONITOR ----
pm1_colocation_with_week <- pm1_colocation %>%
  mutate(week = floor_date(date, "week")) # Extract the week


daily_na <- pm1_colocation_with_week %>%
  group_by(monitor, date) %>%
  summarize(na_percent = sum(is.na(pm1)) / n() * 100) %>%
  ungroup() %>%
  mutate(week = floor_date(date, "week"),  # Extract the week again for plotting
         day_of_week = factor(weekdays(date), 
                              levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")))  # Reorder days of the week
```

```{r colocation missingness heatmap, fig.height=12, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(daily_na, aes(x = week, y = day_of_week, fill = na_percent)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen", na.value = "white") +
  labs(title = "Percentage of Missing PM1 Data by Day During Colocation",
       x = "Week",
       y = "Day of Week",
       fill = "NA Percent") +
  scale_y_discrete(limits = rev(levels(daily_na$day_of_week)),  # Reverse the order to have Sunday at the top
                   breaks = c("Sunday", "Saturday")) +    # Label only specific days
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ monitor, scales = "free_x", ncol = 5)
```


## Community Missingness

```{r missing data, echo=FALSE, message=FALSE, warning=FALSE}
# calculate total missingness across all of the monitors and the entire time range of interest 
overall_missingness <- mean(is.na(pm1_community$pm1)) * 100

# daily missingness  
daily_missingness <- pm1_community %>% 
  group_by(date) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  
  filter(date > as.Date("2023-09-25") & date < as.Date("2024-06-11"))

# hourly missingingness
hourly_missingness <- pm1_community %>% 
  group_by(hour) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100)

#monitor missingness
monitor_missingness <- pm1_community %>% 
  group_by(monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  mutate(monitor = fct_reorder(monitor, -missing_rate))



## DAILY MISSING DATA PERCENTAGE ----

#aggregated across monitors 
ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  geom_line() +
  labs(title = "Daily Missing Data Rate Over Time During Community Deployment", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")


ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  stat_smooth(span = 0.5) +
  labs(title = "Daily Missing Data Rate Over Time During Community Deployment", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")

  


## TOTAL MISSING DATA FOR EACH MONITOR ----

ggplot(monitor_missingness, aes(x = monitor, y = missing_rate)) +
  geom_bar(stat = "identity") +
  labs(title = "Missing Data Rate by Monitor During Community Deployment", x = "Monitor", y = "Missing Data Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 


# MISSING DATA PERCENTAGE FOR EACH HOUR OF THE DAY

#aggregated by monitor 
ggplot(hourly_missingness, aes(x = hour, y = missing_rate)) +
  geom_line() +
  labs(title = "Hourly Missing Data Rate During Community Deployment", x = "Hour of the Day", y = "Missing Data Rate (%)") +
  theme_minimal()

#facet wrap for each monitor 
pm1_community %>% 
  group_by(hour, monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  ggplot(aes(x = hour, y = missing_rate)) +
  geom_line() +
  facet_wrap(~monitor) +
  theme_bw() +
  labs(title = "Hourly Missing Data Rate for Each Monitor During Community Deployment", x = "Hour of the Day", y = "Missing Data Rate (%)") +
  theme_minimal()


# MAP OF MONITOR MISSINGNESS BY LOCATION ----
missing_monitor_location <- left_join(monitor_missingness, monitor_points)

ggplot() +
  # Add Ghana regions within the bounding box
  geom_sf(data = regions, fill = ifelse(regions$region == "Bono East", "#f5e493", "lightblue"), color = "black", alpha = 0.5) +
  
  # Add monitor points with transparency within the bounding box
  geom_sf(data = missing_monitor_location, aes(geometry = geometry, color = missing_rate), alpha = 0.7, size = 5) +

  # Zoom in to the bounding box
  coord_sf(xlim = c(-2.2, -1.3), ylim = c(7.6, 8.8), expand = FALSE) +
  
  # Customize
  labs(title = "Monitor Missing Data and Location",
       x = "", 
       y = "") +
  theme_bw() +
  scale_color_gradient(low = "#0540a1", high = "#eb4c2d", name = "Missing Rate (%)")
```

### Spatial Correlation of Missing Data 
```{r spatial missing data, echo=FALSE, message=FALSE, warning=FALSE}
# Convert to an sf object
missing_monitor_location <- st_as_sf(missing_monitor_location)

coords <- st_coordinates(missing_monitor_location)
nb <- knn2nb(knearneigh(coords, k = 5)) # k-nearest neighbors
listw <- nb2listw(nb, style = "W")
  
# Calculate Moran's I
moran_result <- moran.test(missing_monitor_location$missing_rate, listw)

# Extract relevant values directly
observed_value <- as.numeric(moran_result$estimate["Moran I statistic"])
expected_value <- as.numeric(moran_result$estimate["Expectation"])
variance <- as.numeric(moran_result$estimate["Variance"])
z_score <- as.numeric(moran_result$statistic)
p_value <- as.numeric(moran_result$p.value)

# Create the Moran's I results table
moran_table <- data.frame(
  Test = "Moran's I Statistic",
  `Observed Value` = observed_value,
  `Expected Value` = expected_value,
  `Variance` = variance,
  `Z-score` = z_score,
  `p-value` = p_value
)

moran_table
```

**Interpretation of Moran I Statistic**

-   -1: The variable of interest is perfectly dispersed

-   0: The variable of interest is randomly dispersed

-   1: The variable of interest is perfectly clustered together

```{r missingness heat map, fig.height=16, fig.width=9, echo=FALSE, message=FALSE, warning=FALSE}
## HEATMAP OF MISSINGNESS PER DAY FOR EACH MONITOR ----
pm1_community_with_week <- pm1_community %>%
  mutate(week = floor_date(date, "week")) # Extract the week


daily_na <- pm1_community_with_week %>%
  group_by(monitor, date) %>%
  summarize(na_percent = sum(is.na(pm1)) / n() * 100) %>%
  ungroup() %>%
  mutate(week = floor_date(date, "week"),  # Extract the week again for plotting
         day_of_week = factor(weekdays(date), 
                              levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")))  # Reorder days of the week

ggplot(daily_na, aes(x = week, y = day_of_week, fill = na_percent)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen", na.value = "white") +
  labs(title = "Percentage of Missing PM1 Data by Day During Community Deployment",
       x = "Week",
       y = "Day of Week",
       fill = "NA Percent") +
  scale_y_discrete(limits = rev(levels(daily_na$day_of_week)),  # Reverse the order to have Sunday at the top
                   breaks = c("Sunday", "Saturday")) +    # Label only specific days
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ monitor, scales = "free_x", ncol = 5)
```


# Pollutant Trends

```{r, echo=FALSE, message=FALSE, warning=FALSE}
## LOAD IN THE DATA THAT CONTAINS SD CARD INFO ----

# List all MOD files with full path
mod_files <- list.files(
  path = "/Users/lewiswhite/CHAP_columbia/QuantAQ/SD_data/MOD", 
  full.names = TRUE, 
  recursive = FALSE, 
  pattern = "MOD-00.*\\.csv"
)

# List all MOD-PM files with full path
mod_pm_files <- list.files(
  path = "/Users/lewiswhite/CHAP_columbia/QuantAQ/SD_data/MOD-PM", 
  full.names = TRUE, 
  recursive = FALSE, 
  pattern = "MOD-PM.*\\.csv"
)

# Function to read, select columns, and add monitor name for MOD files
read_and_select_mod <- function(file) {
  # Extract the monitor name from the file name
  monitor_name <- str_extract(basename(file), "MOD-\\d+")
  
  read_csv(file) %>%
    select(timestamp_iso, co:pm25) %>%
    mutate(monitor = monitor_name)
}

# Function to read, select columns, and add monitor name for MOD-PM files
read_and_select_mod_pm <- function(file) {
  # Extract the monitor name from the file name
  monitor_name <- str_extract(basename(file), "MOD-PM-\\d+")
  
  read_csv(file) %>%
    select(timestamp_iso, pm1:pm25) %>%
    mutate(monitor = monitor_name)
}

# Read all MOD files and combine them
MOD_sd_card <- mod_files %>%
  map_dfr(read_and_select_mod)

# Read all MOD-PM files and combine them
MOD_PM_sd_card <- mod_pm_files %>%
  map_dfr(read_and_select_mod_pm)

MOD_PM_sd_card <- MOD_PM_sd_card %>%
  mutate(co = NA_real_,
         no = NA_real_,
         no2 = NA_real_,
         o3 = NA_real_) %>%
  select(timestamp_iso, co, no, no2, o3, pm1, pm10, pm25, monitor)

full_sd_card = rbind(MOD_sd_card, MOD_PM_sd_card)

## MERGE THE SD DATA WITH THE SERVER DATA ---- 

# List of pollutants you want to process
pollutants <- c("pm1", "pm25", "pm10")

raw_data <- list()

for (pollutant in pollutants) {
  load_pollution_datasets(pollutant)
  # Store the raw data
  raw_data[[paste0(pollutant, "_raw")]] <- get(paste0(pollutant, "_raw"))
}

# Process the pollutants
results <- process_multiple_pollutants(pollutants, raw_data, full_sd_card)

pm1_colocation_hourly <- results$pm1$hourly %>% filter(date >= as.Date("2023-08-16") & date <= as.Date("2023-09-20"))
pm1_colocation_daily <- results$pm1$daily %>% filter(date >= as.Date("2023-08-16") & date <= as.Date("2023-09-20"))
pm10_colocation_hourly <- results$pm10$hourly %>% filter(date >= as.Date("2023-08-16") & date <= as.Date("2023-09-20"))
pm10_colocation_daily <- results$pm10$daily %>% filter(date >= as.Date("2023-08-16") & date <= as.Date("2023-09-20"))
pm25_colocation_hourly <- results$pm25$hourly %>% filter(date >= as.Date("2023-08-16") & date <= as.Date("2023-09-20"))
pm25_colocation_daily <- results$pm25$daily %>% filter(date >= as.Date("2023-08-16") & date <= as.Date("2023-09-20"))
pm1_community_hourly <- results$pm1$hourly %>% filter(date >= as.Date("2023-09-26"))
pm1_community_daily <- results$pm1$daily %>% filter(date >= as.Date("2023-09-26"))
pm10_community_hourly <- results$pm10$hourly %>% filter(date >= as.Date("2023-09-26"))
pm10_community_daily <- results$pm10$daily %>% filter(date >= as.Date("2023-09-26"))
pm25_community_hourly <- results$pm25$hourly %>% filter(date >= as.Date("2023-09-26"))
pm25_community_daily <- results$pm25$daily %>% filter(date >= as.Date("2023-09-26"))

```



## Grand Average plots 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
daily_pollutants <- left_join(pm1_community_daily, pm25_community_daily) %>% 
  left_join(pm10_community_daily)

daily_pollutants_long <- daily_pollutants %>%
  group_by(date) %>%
  summarise('Mean PM 1' = mean(mean_pm1, na.rm = TRUE),
            'Mean PM 2.5' = mean(mean_pm25, na.rm = TRUE),
            'Mean PM 10' = mean(mean_pm10, na.rm = TRUE)) %>%
  ungroup() %>%
  pivot_longer(cols = c("Mean PM 1", "Mean PM 2.5", "Mean PM 10"), names_to = "pollutant", values_to = "measurement")

# Convert the 'pollutant' column to a factor with the desired order
daily_pollutants_long$pollutant <- factor(daily_pollutants_long$pollutant, levels = c("Mean PM 1", "Mean PM 2.5", "Mean PM 10"))

daily_pollutants_long %>%
  ggplot(aes(x = date, y = measurement)) +
  geom_line() +
  theme_bw() +
  labs(x = "Date",
       y = "Pollutant Measurement",
       title = "Average Daily Particulate Matter Levels Across All Monitors") +
  facet_grid(pollutant ~ ., scales = "free_y")


daily_pollutants_long %>%
  ggplot(aes(x = date, y = measurement)) +
  geom_smooth() +
  theme_bw() +
  labs(x = "Date",
       y = "Pollutant Measurement",
       title = "Average Daily Particulate Matter Levels Across All Monitors") +
  facet_grid(pollutant ~ ., scales = "free_y")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
mod_sep_daily_pollutants_long <- daily_pollutants %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date) %>%
  summarize(across(where(is.numeric), list(mean = mean), na.rm = TRUE)) %>%
  ungroup() %>%
  rename("Mean PM 1" = mean_pm1_mean, 
         "Mean PM 2.5" = mean_pm25_mean,
         "Mean PM 10" = mean_pm10_mean) %>%
  
  pivot_longer(cols = c("Mean PM 1", "Mean PM 2.5", "Mean PM 10"), names_to = "pollutant", values_to = "measurement") %>%
  
  mutate(mod_pm = case_when(mod_pm == "FALSE" ~ "MOD Device",
                            mod_pm == "TRUE" ~ "MOD-PM Device"))
  

mod_sep_daily_pollutants_long$pollutant <- factor(mod_sep_daily_pollutants_long$pollutant, levels = c("Mean PM 1", "Mean PM 2.5", "Mean PM 10"))
  

mod_sep_daily_pollutants_long %>%
  ggplot(aes(x = date, y = measurement)) +
  geom_line() +
  theme_bw() +
  labs(x = "Date",
       y = "Pollutant Measurement",
       title = "Average Daily Particulate Matter Levels Across Monitors",
       subtitle = "Comparing MOD devices to MOD-PM devices") +
  facet_grid(pollutant ~ mod_pm, scales = "free_y")
```




```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary_data <- daily_pollutants %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date) %>%
  summarize(across(where(is.numeric), list(mean = mean), na.rm = TRUE), .groups = 'drop') %>%
  ungroup() %>%
  group_by(mod_pm, date) %>%
  summarize(mean_pm1 = mean(mean_pm1_mean, na.rm = TRUE),
            mean_pm25 = mean(mean_pm25_mean, na.rm = TRUE),
            mean_pm10 = mean(mean_pm10_mean, na.rm = TRUE), .groups = 'drop') %>%
  filter(mod_pm == TRUE)

# Calculate distribution statistics
distribution_stats <- summary_data %>%
  summarize(Statistic = c("Min", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max"),
            PM1 = round(c(min(mean_pm1, na.rm = TRUE),
                    quantile(mean_pm1, 0.25, na.rm = TRUE),
                    median(mean_pm1, na.rm = TRUE),
                    mean(mean_pm1, na.rm = TRUE),
                    quantile(mean_pm1, 0.75, na.rm = TRUE),
                    max(mean_pm1, na.rm = TRUE)), 2),
            PM25 = round(c(min(mean_pm25, na.rm = TRUE),
                     quantile(mean_pm25, 0.25, na.rm = TRUE),
                     median(mean_pm25, na.rm = TRUE),
                     mean(mean_pm25, na.rm = TRUE),
                     quantile(mean_pm25, 0.75, na.rm = TRUE),
                     max(mean_pm25, na.rm = TRUE)), 2),
            PM10 = round(c(min(mean_pm10, na.rm = TRUE),
                     quantile(mean_pm10, 0.25, na.rm = TRUE),
                     median(mean_pm10, na.rm = TRUE),
                     mean(mean_pm10, na.rm = TRUE),
                     quantile(mean_pm10, 0.75, na.rm = TRUE),
                     max(mean_pm10, na.rm = TRUE)), 2))

# Create the table using kable and kableExtra
kable(distribution_stats, format = "html", col.names = c("Statistic", "PM1", "PM2.5", "PM10")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE) %>%
  add_header_above(c(" " = 1, "MOD-PM Device Pollutant Daily Distribution" = 3)) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, bold = TRUE)






# Assuming you have your summary data in a dataframe called summary_data
summary_data <- daily_pollutants %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date) %>%
  summarize(across(where(is.numeric), list(mean = mean), na.rm = TRUE), .groups = 'drop') %>%
  ungroup() %>%
  group_by(mod_pm, date) %>%
  summarize(mean_pm1 = mean(mean_pm1_mean, na.rm = TRUE),
            mean_pm25 = mean(mean_pm25_mean, na.rm = TRUE),
            mean_pm10 = mean(mean_pm10_mean, na.rm = TRUE), .groups = 'drop') %>%
  filter(mod_pm == FALSE)

# Calculate distribution statistics
distribution_stats <- summary_data %>%
  summarize(Statistic = c("Min", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max"),
            PM1 = round(c(min(mean_pm1, na.rm = TRUE),
                    quantile(mean_pm1, 0.25, na.rm = TRUE),
                    median(mean_pm1, na.rm = TRUE),
                    mean(mean_pm1, na.rm = TRUE),
                    quantile(mean_pm1, 0.75, na.rm = TRUE),
                    max(mean_pm1, na.rm = TRUE)), 2),
            PM25 = round(c(min(mean_pm25, na.rm = TRUE),
                     quantile(mean_pm25, 0.25, na.rm = TRUE),
                     median(mean_pm25, na.rm = TRUE),
                     mean(mean_pm25, na.rm = TRUE),
                     quantile(mean_pm25, 0.75, na.rm = TRUE),
                     max(mean_pm25, na.rm = TRUE)), 2),
            PM10 = round(c(min(mean_pm10, na.rm = TRUE),
                     quantile(mean_pm10, 0.25, na.rm = TRUE),
                     median(mean_pm10, na.rm = TRUE),
                     mean(mean_pm10, na.rm = TRUE),
                     quantile(mean_pm10, 0.75, na.rm = TRUE),
                     max(mean_pm10, na.rm = TRUE)), 2))

# Create the table using kable and kableExtra
kable(distribution_stats, format = "html", col.names = c("Statistic", "PM1", "PM2.5", "PM10")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE) %>%
  add_header_above(c(" " = 1, "MOD Device Pollutant Daily Distribution" = 3)) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, bold = TRUE)
```



## PM 2.5 Colocation 

### Data Quality Check: Comparing PM 2.5 From Individual Monitors to Fleet Average

```{r colocation monitor fleet avg 25, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm25_colocation_hourly, "pm25", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm25_colocation_daily, "pm25", "daily")
```

#### PM 2.5 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm25_hourly_regression_data <- pm25_colocation_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm25))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm25_colocation_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm25))


pm25_colocation_regression_results <- apply_regression(pm25_hourly_regression_data, "mean_pm25", "fleet_average_pm25")

datatable(pm25_colocation_regression_results)
```

#### PM 2.5 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm25_daily_regression_data <- pm25_colocation_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm25))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm25_colocation_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm25))


pm25_colocation_regression_results <- apply_regression(pm25_daily_regression_data, "mean_pm25", "fleet_average_pm25")

datatable(pm25_colocation_regression_results)
```

### PM 2.5 Colocation MOD vs MOD-PM measures to check consistency

```{r, echo=FALSE, message=FALSE, warning=FALSE}
mod_pm_pm25 <- pm25_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm25, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == TRUE)

mod_pm25 <- pm25_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm25, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == FALSE)

# Extract the mean_hourly_pm vectors
MOD_PM_pm25_means <- mod_pm_pm25$mean_hourly_pm
MOD_pm25_means <- mod_pm25$mean_hourly_pm

# Perform t-test
t_test_result <- t.test(MOD_PM_pm25_means, MOD_pm25_means)

# Print the result
print(t_test_result)
```


### PM 2.5 Trend Heatmap

```{r colocation pm25 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm25_colocation_hourly, "pm25")
```

## PM 2.5 Community Deployment

### Checking Individual Monitor to Fleet Average

```{r monitor vs fleet avg 25, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm25_community_hourly, "pm25", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm25_community_daily, "pm25", "daily")
```

#### PM 2.5 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm25_hourly_regression_data <- pm25_community_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm25))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm25_community_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm25))


pm25_colocation_regression_results <- apply_regression(pm25_hourly_regression_data, "mean_pm25", "fleet_average_pm25")

datatable(pm25_colocation_regression_results)
```

#### PM 2.5 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm25_daily_regression_data <- pm25_community_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm25))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm25_community_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm25))


pm25_colocation_regression_results <- apply_regression(pm25_daily_regression_data, "mean_pm25", "fleet_average_pm25")

datatable(pm25_colocation_regression_results)
```


### PM 2.5 Trends

```{r pm25 timelines, echo=FALSE, message=FALSE, warning=FALSE}
daily_pm25_all_devices <- pm25_community %>%
  group_by(date, monitor) %>%
  summarize(mean_pm25 = mean(pm25, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm25, group = monitor)) +
  geom_line(color = "black", alpha = 0.2) +
  theme_minimal() +
  labs(y = "Mean PM 2.5",
       title = "Average PM 2.5 Accross All Devices")

daily_cooktime_pm25_all_devices <- pm25_community %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(monitor, date) %>%
  summarise(mean_pm25 = mean(pm25, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm25, group = monitor)) +
  geom_line(color = "black", alpha = 0.4) +
  theme_minimal() +
  labs(y = "Mean PM 2.5",
       title = "Daily Average PM 2.5 for Each Monitor During Primary Cooking Hours (3-7)") 

grid.arrange(daily_pm25_all_devices, daily_cooktime_pm25_all_devices)

daily_pm25_timeline <- pm25_community %>%
  group_by(date) %>%
  summarize(mean_pm25 = mean(pm25, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm25)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 2.5",
       title = "Average PM 2.5 Accross All Devices")

daily_cooktime_pm25_timeline <- pm25_community %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(date) %>%
  summarize(mean_pm25 = mean(pm25, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm25)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 2.5",
       title = "Mean PM 2.5 Accross All Devices During Cooking Hours (3-7)")

grid.arrange(daily_pm25_timeline, daily_cooktime_pm25_timeline)
```

### PM 2.5 Heatmap

```{r pm25 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm25_community_hourly, "pm25")
```

### Spatial Correlation

```{r spatial correlation 25, echo=FALSE, message=FALSE, warning=FALSE}
generate_spatial_pollution_map(pm25_community, "pm25", missing_monitor_location)
```

### Calculate Moran I for Spatial Correlation

```{r moran i 25, echo=FALSE, message=FALSE, warning=FALSE}
calculate_moran_i(pm25_community, "pm25", missing_monitor_location)
```

**Interpretation of Moran I Statistic**

-   -1: The variable of interest is perfectly dispersed

-   0: The variable of interest is randomly dispersed

-   1: The variable of interest is perfectly clustered together

### Including proximity to road

```{r road 25, echo=FALSE, message=FALSE, warning=FALSE}
monitor_sf_road_dist <- prep_monitor_road_data(pm25_community, "pm25", missing_monitor_location, roads)

generate_spatial_pollution_road_map(monitor_sf_road_dist, roads_filtered, "pm25")

pm25_regression_results <- regress_polutant_road(monitor_sf_road_dist, "pm25")

pm25_regression_results$plot

pm25_regression_results$summary_table
```


## PM 1 Colocation 

### Data Quality Check: Comparing PM 1 From Individual Monitors to Fleet Average

```{r colocation monitor fleet avg 1, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm1_colocation_hourly, "pm1", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm1_colocation_daily, "pm1", "daily")
```

#### PM 1 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm1_hourly_regression_data <- pm1_colocation_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm1))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm1_colocation_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm1))


pm1_colocation_regression_results <- apply_regression(pm1_hourly_regression_data, "mean_pm1", "fleet_average_pm1")

datatable(pm1_colocation_regression_results)
```

#### PM 1 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm1_daily_regression_data <- pm1_colocation_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm1))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm1_colocation_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm1))


pm1_colocation_regression_results <- apply_regression(pm1_daily_regression_data, "mean_pm1", "fleet_average_pm1")

datatable(pm1_colocation_regression_results)
```

### PM 1 Colocation MOD vs MOD-PM measures to check consistency

```{r, echo=FALSE, message=FALSE, warning=FALSE}
mod_pm_pm1 <- pm1_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm1, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == TRUE)

mod_pm1 <- pm1_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm1, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == FALSE)

# Extract the mean_hourly_pm vectors
MOD_PM_hourly_pm1_means <- mod_pm_pm1$mean_hourly_pm
MOD_hourly_pm1_means <- mod_pm1$mean_hourly_pm

# Perform t-test
t_test_result <- t.test(MOD_PM_hourly_pm1_means, MOD_hourly_pm1_means)

# Print the result
print(t_test_result)
```



### PM 1 Trend Heatmap

```{r colocation pm1 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm1_colocation_hourly, "pm1")
```

## PM 1 Community Deployment

### Checking Individual Monitor to Fleet Average

```{r monitor vs fleet avg 1, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm1_community_hourly, "pm1", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm1_community_daily, "pm1", "daily")
```

#### PM 1 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm1_hourly_regression_data <- pm1_community_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm1))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm1_community_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm1))


pm1_colocation_regression_results <- apply_regression(pm1_hourly_regression_data, "mean_pm1", "fleet_average_pm1")

datatable(pm1_colocation_regression_results)
```

#### PM 1 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm1_daily_regression_data <- pm1_community_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm1))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm1_community_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm1))


pm1_colocation_regression_results <- apply_regression(pm1_daily_regression_data, "mean_pm1", "fleet_average_pm1")

datatable(pm1_colocation_regression_results)
```


### PM 1 Trends

```{r pm1 timelines, echo=FALSE, message=FALSE, warning=FALSE}
daily_pm1_all_devices <- pm1_community %>%
  group_by(date, monitor) %>%
  summarize(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1, group = monitor)) +
  geom_line(color = "black", alpha = 0.2) +
  theme_minimal() +
  labs(y = "Mean PM 1",
       title = "Average PM 1 Accross All Devices")

daily_cooktime_pm1_all_devices <- pm1_community %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(monitor, date) %>%
  summarise(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1, group = monitor)) +
  geom_line(color = "black", alpha = 0.4) +
  theme_minimal() +
  labs(y = "Mean PM 1 ",
       title = "Daily Average PM 1 for Each Monitor During Primary Cooking Hours (3-7)") 

grid.arrange(daily_pm1_all_devices, daily_cooktime_pm1_all_devices)

daily_pm1_timeline <- pm1_community %>%
  group_by(date) %>%
  summarize(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 1",
       title = "Average PM 1 Accross All Devices")

daily_cooktime_pm1_timeline <- pm1_community %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(date) %>%
  summarize(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 1",
       title = "Mean PM 1 Accross All Devices During Cooking Hours (3-7)")

grid.arrange(daily_pm1_timeline, daily_cooktime_pm1_timeline)
```

### PM 1 Heatmap

```{r pm1 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm1_community_hourly, "pm1")
```


### Spatial Correlation

```{r spatial correlation 1, echo=FALSE, message=FALSE, warning=FALSE}
generate_spatial_pollution_map(pm1_community, "pm1", missing_monitor_location)
```

### Calculate Moran I for Spatial Correlation

```{r moran i 1, echo=FALSE, message=FALSE, warning=FALSE}
calculate_moran_i(pm1_community, "pm1", missing_monitor_location)
```

**Interpretation of Moran I Statistic**

-   -1: The variable of interest is perfectly dispersed

-   0: The variable of interest is randomly dispersed

-   1: The variable of interest is perfectly clustered together

### Including proximity to road

```{r road 1, echo=FALSE, message=FALSE, warning=FALSE}
monitor_sf_road_dist <- prep_monitor_road_data(pm1_community, "pm1", missing_monitor_location, roads)

generate_spatial_pollution_road_map(monitor_sf_road_dist, roads_filtered, "pm1")

pm1_regression_results <- regress_polutant_road(monitor_sf_road_dist, "pm1")

pm1_regression_results$plot

pm1_regression_results$summary_table
```




## PM 10 Colocation 

### Data Quality Check: Comparing PM 10 From Individual Monitors to Fleet Average

```{r colocation monitor fleet avg 10, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm10_colocation_hourly, "pm10", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm10_colocation_daily, "pm10", "daily")
```

#### PM 10 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_hourly_regression_data <- pm10_colocation_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_colocation_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_hourly_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```

#### PM 10 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_daily_regression_data <- pm10_colocation_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_colocation_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_daily_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```


### PM 10 Colocation MOD vs MOD-PM measures to check consistency

```{r, echo=FALSE, message=FALSE, warning=FALSE}
mod_pm_pm10 <- pm10_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm10, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == TRUE)

mod_pm10 <- pm10_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm10, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == FALSE)

# Extract the mean_hourly_pm vectors
MOD_PM_pm10_means <- mod_pm_pm10$mean_hourly_pm
MOD_pm10_means <- mod_pm10$mean_hourly_pm

# Perform t-test
t_test_result <- t.test(MOD_PM_pm10_means, MOD_pm10_means)

# Print the result
print(t_test_result)
```



### PM 10 Trend Heatmap

```{r colocation pm10 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm10_colocation_hourly, "pm10")
```

## PM 10 Community Deployment

### Checking Individual Monitor to Fleet Average

```{r monitor vs fleet avg 10, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm10_community_hourly, "pm10", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm10_community_daily, "pm10", "daily")
```


#### PM 10 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_hourly_regression_data <- pm10_community_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_community_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_hourly_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```

#### PM 10 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_daily_regression_data <- pm10_community_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_community_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_daily_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```


### PM 10 Trends

```{r pm10 timeline, echo=FALSE, message=FALSE, warning=FALSE}
daily_pm10_all_devices <- pm10_community %>%
  group_by(date, monitor) %>%
  summarize(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10, group = monitor)) +
  geom_line(color = "black", alpha = 0.2) +
  theme_minimal() +
  labs(y = "Mean PM 10",
       title = "Average PM 10 Accross All Devices")

daily_cooktime_pm10_all_devices <- pm10_community %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(monitor, date) %>%
  summarise(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10, group = monitor)) +
  geom_line(color = "black", alpha = 0.4) +
  theme_minimal() +
  labs(y = "Mean PM 10 ",
       title = "Daily Average PM 10 for Each Monitor During Primary Cooking Hours (3-7)") 

grid.arrange(daily_pm10_all_devices, daily_cooktime_pm10_all_devices)

daily_pm10_timeline <- pm10_community %>%
  group_by(date) %>%
  summarize(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 10",
       title = "Average PM 10 Accross All Devices")

daily_cooktime_pm10_timeline <- pm10_community %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(date) %>%
  summarize(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 10",
       title = "Mean PM 10 Accross All Devices During Cooking Hours (3-7)")

grid.arrange(daily_pm10_timeline, daily_cooktime_pm10_timeline)
```

### PM 10 Trend Heatmap

```{r pm10 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm10_community_hourly, "pm10")
```

### Spatial Correlation

```{r spatial correlation 10, echo=FALSE, message=FALSE, warning=FALSE}
generate_spatial_pollution_map(pm10_community, "pm10", missing_monitor_location)
```

### Calculate Moran I for Spatial Correlation

```{r moran i 10, echo=FALSE, message=FALSE, warning=FALSE}
calculate_moran_i(pm10_community, "pm10", missing_monitor_location)
```

**Interpretation of Moran I Statistic**

-   -1: The variable of interest is perfectly dispersed

-   0: The variable of interest is randomly dispersed

-   1: The variable of interest is perfectly clustered together

### Including proximity to road

```{r road 10, echo=FALSE, message=FALSE, warning=FALSE}
monitor_sf_road_dist <- prep_monitor_road_data(pm10_community, "pm10", missing_monitor_location, roads)

generate_spatial_pollution_road_map(monitor_sf_road_dist, roads_filtered, "pm10")

pm10_regression_results <- regress_polutant_road(monitor_sf_road_dist, "pm10")

pm10_regression_results$plot
pm10_regression_results$summary_table
```



## PM 10 Colocation Revisited Without Outliers (All pollution levels above 1000 set to 1000)
```{r recalc pm10 data no outlier, echo=FALSE, message=FALSE, warning=FALSE}
pm10_colocation <- pm10_colocation %>%
  mutate(pm10 = case_when(pm10 > 1000 ~ 1000,
                          TRUE ~ pm10))

pm10_colocation_hourly <- pm10_colocation_hourly %>%
  mutate(mean_pm10 = case_when(mean_pm10 > 1000 ~ 1000,
                          TRUE ~ mean_pm10)) %>%
  mutate(fleet_average_pm10 = case_when(fleet_average_pm10 > 1000 ~ 1000,
                                        TRUE ~ fleet_average_pm10))

pm10_colocation_daily <- pm10_colocation_daily %>%
  mutate(mean_pm10 = case_when(mean_pm10 > 1000 ~ 1000,
                          TRUE ~ mean_pm10)) %>%
  mutate(fleet_average_pm10 = case_when(fleet_average_pm10 > 1000 ~ 1000,
                                        TRUE ~ fleet_average_pm10))


pm10_community <- pm10_community %>%
  mutate(pm10 = case_when(pm10 > 1000 ~ 1000,
                          TRUE ~ pm10))

pm10_community_hourly <- pm10_community_hourly %>%
  mutate(mean_pm10 = case_when(mean_pm10 > 1000 ~ 1000,
                          TRUE ~ mean_pm10)) %>%
  mutate(fleet_average_pm10 = case_when(fleet_average_pm10 > 1000 ~ 1000,
                                        TRUE ~ fleet_average_pm10))

pm10_community_daily <- pm10_community_daily %>%
  mutate(mean_pm10 = case_when(mean_pm10 > 1000 ~ 1000,
                          TRUE ~ mean_pm10)) %>%
  mutate(fleet_average_pm10 = case_when(fleet_average_pm10 > 1000 ~ 1000,
                                        TRUE ~ fleet_average_pm10))
```

### Data Quality Check: Comparing PM 10 From Individual Monitors to Fleet Average

```{r colocation monitor fleet avg 10 no outlier, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm10_colocation_hourly, "pm10", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm10_colocation_daily, "pm10", "daily")
```


#### PM 10 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_hourly_regression_data <- pm10_colocation_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_colocation_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_hourly_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```

#### PM 10 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_daily_regression_data <- pm10_colocation_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_colocation_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_daily_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```


### PM 10 Colocation MOD vs MOD-PM measures to check consistency

```{r, echo=FALSE, message=FALSE, warning=FALSE}
mod_pm_pm10 <- pm10_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm10, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == TRUE)

mod_pm10 <- pm10_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm10, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == FALSE)

# Extract the mean_hourly_pm vectors
MOD_PM_pm10_means <- mod_pm_pm10$mean_hourly_pm
MOD_pm10_means <- mod_pm10$mean_hourly_pm

# Perform t-test
t_test_result <- t.test(MOD_PM_pm10_means, MOD_pm10_means)

# Print the result
print(t_test_result)
```


### PM 10 Trend Heatmap

```{r colocation pm10 trends no outlier, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm10_colocation_hourly, "pm10")
```


## PM 10 Community Revisited Without Outliers (All pollution levels above 1000 set to 1000)

### Checking Individual Monitor to Fleet Average

```{r monitor vs fleet avg 10 no outlier, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm10_community_hourly, "pm10", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm10_community_daily, "pm10", "daily")
```


#### PM 10 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_hourly_regression_data <- pm10_community_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_community_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_hourly_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```

#### PM 10 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_daily_regression_data <- pm10_community_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_community_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_daily_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```


### PM 10 Trends

```{r pm10 timeline no outlier, echo=FALSE, message=FALSE, warning=FALSE}
daily_pm10_all_devices <- pm10_community %>%
  group_by(date, monitor) %>%
  summarize(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10, group = monitor)) +
  geom_line(color = "black", alpha = 0.2) +
  theme_minimal() +
  labs(y = "Mean PM 10",
       title = "Average PM 10 Accross All Devices")

daily_cooktime_pm10_all_devices <- pm10_community %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(monitor, date) %>%
  summarise(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10, group = monitor)) +
  geom_line(color = "black", alpha = 0.4) +
  theme_minimal() +
  labs(y = "Mean PM 10 ",
       title = "Daily Average PM 10 for Each Monitor During Primary Cooking Hours (3-7)") 

grid.arrange(daily_pm10_all_devices, daily_cooktime_pm10_all_devices)

daily_pm10_timeline <- pm10_community %>%
  group_by(date) %>%
  summarize(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 10",
       title = "Average PM 10 Accross All Devices")

daily_cooktime_pm10_timeline <- pm10_community %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(date) %>%
  summarize(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 10",
       title = "Mean PM 10 Accross All Devices During Cooking Hours (3-7)")

grid.arrange(daily_pm10_timeline, daily_cooktime_pm10_timeline)
```

### PM 10 Trend Heatmap

```{r pm10 trends no outlier, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm10_community_hourly, "pm10")
```

### Spatial Correlation

```{r spatial correlation 10 no outlier, echo=FALSE, message=FALSE, warning=FALSE}
generate_spatial_pollution_map(pm10_community, "pm10", missing_monitor_location)
```

### Calculate Moran I for Spatial Correlation

```{r moran i 10 no outlier, echo=FALSE, message=FALSE, warning=FALSE}
calculate_moran_i(pm10_community, "pm10", missing_monitor_location)
```

**Interpretation of Moran I Statistic**

-   -1: The variable of interest is perfectly dispersed

-   0: The variable of interest is randomly dispersed

-   1: The variable of interest is perfectly clustered together

### Including proximity to road

```{r road 10 no outlier, echo=FALSE, message=FALSE, warning=FALSE}
monitor_sf_road_dist <- prep_monitor_road_data(pm10_community, "pm10", missing_monitor_location, roads)

generate_spatial_pollution_road_map(monitor_sf_road_dist, roads_filtered, "pm10")

pm10_regression_results <- regress_polutant_road(monitor_sf_road_dist, "pm10")

pm10_regression_results$plot
pm10_regression_results$summary_table
```





# Gas Trends


Questions:
* What is an outlier worth removing?
* The spatial stuff doesn't make sense to include here, right?

```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot_daily_mean_pollutant <- function(data, pollutant_measurement, title = NULL) {
  pollutant_col <- sym(paste0("mean_", pollutant_measurement))
  
  ggplot(data, aes(x = date, y = !!pollutant_col)) +
    geom_line() +
    facet_wrap(~monitor, ncol = 2) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Rotate x-axis labels
    labs(x = "Date",
         y = paste("Daily Mean", toupper(pollutant_measurement)),
         title = title)
}

plot_co_col_time <- plot_daily_mean_pollutant(co_colocation_daily, "co", "Colocation Daily Mean CO by Monitor over Time")

plot_co_com_time <- plot_daily_mean_pollutant(co_community_daily, "co", "Community Daily Mean CO by Monitor over Time")

plot_no_col_time <- plot_daily_mean_pollutant(no_colocation_daily, "no", "Colocation Daily Mean NO by Monitor over Time")

plot_no_com_time <- plot_daily_mean_pollutant(no_community_daily, "no", "Community Daily Mean NO by Monitor over Time")

plot_no2_col_time <- plot_daily_mean_pollutant(no2_colocation_daily, "no2", "Colocation Daily Mean NO2 by Monitor over Time")

plot_no2_com_time <- plot_daily_mean_pollutant(no2_community_daily, "no2", "Community Daily Mean NO2 by Monitor over Time")

plot_o3_col_time <- plot_daily_mean_pollutant(o3_colocation_daily, "o3", "Colocation Daily Mean O3 by Monitor over Time")

plot_o3_com_time <- plot_daily_mean_pollutant(o3_community_daily, "o3", "Community Daily Mean O3 by Monitor over Time")


grid.arrange(plot_co_col_time, plot_no_col_time, plot_no2_col_time, plot_o3_col_time)

grid.arrange(plot_co_com_time, plot_no_com_time, plot_no2_com_time, plot_o3_com_time)


```

Golden Monitor = MOD-00397

```{r, echo=FALSE, message=FALSE, warning=FALSE}
golden_mod_co_colocation_hourly <- co_colocation_hourly %>% filter(monitor == "MOD-00397") %>%
  mutate(monitor_00397 = mean_co) %>%
  select(monitor_00397, date, hour)

co_colocation_hourly_full <- co_colocation_hourly %>%
  left_join(golden_mod_co_colocation_hourly) %>%
  filter(date < as.Date("2023-08-20"))

co_colocation_hourly_full %>%
  ggplot(aes(x = monitor_00397, y = mean_co)) +
  geom_point(alpha = 0.4) +
  facet_wrap(~monitor) +
  theme_bw() +
  labs(x = "MOD-00397 Hourly CO",
       y = "MOD Hourly CO",
       title = "Comparing Hourly CO to Monitor 00379 Readings")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm25_hourly_regression_data <- pm25_colocation_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm25))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm25_colocation_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm25))


co_colocation_regression_results <- apply_regression(t, "mean_co", "monitor_00397")

datatable(co_colocation_regression_results)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(co_colocation_hourly, "co")
```


