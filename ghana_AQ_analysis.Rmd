---
title: "Ghana Air Quality Analysis"
output: html_document
date: "2024-06-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
### load packages 
library(here) 
library(lubridate) 
library(tictoc)
library(DT)
library(purrr)
library(tidyverse)
library(data.table)
library(sf)
library(viridis)
library(knitr)
library(modelsummary)
library(spdep)
library(gstat)
library(units) 
```


```{r}
# Source in functions

# source in function that loads each pollution dataset separately to keep data small and prevent R crashes 
source(here("src", "load_pollution_datasets.R"))

# source function that aggregates data by time scale of interest (hourly, daily)
source(here("src", "summarize_pollution_times.R"))

# Source function that creates fleet average vs monitor pollutant reading plot
source(here("src", "compare_fleet_avg_monitor.R"))

# Source function that creates heatmap of pollutant readings
source(here("src", "generate_heatmap.R"))

# Source function to make map of pollution values at each monitor location
source(here("src", "generate_spatial_pollution_map.R"))

# source function to calculate moran i 
source(here("src", "calculate_moran_i.R"))

# source function to prepare data for road regression analysis and plotting
source(here("src", "prep_monitor_road_data.R"))

# source function to plot map of pollutant levels by location with roads 
source(here("src", "generate_spatial_pollution_road_map.R"))

# source function to run regression analysis on pollutant / distance to road
source(here("src", "regress_pollutant_road.R"))

```


```{r location data, echo=FALSE, message=FALSE, warning=FALSE}
#LOAD LOCATION DATA ----

# identify the location columns
location_columns <- c("monitor", "geo_lat", "geo_lon", "date")

# read in the monitor location data using fread to handle large dataset
location_data <- fread("/Users/lewiswhite/CHAP_columbia/QuantAQ/ghana_AQ_parent_full.csv", 
                       select = location_columns, 
                       showProgress = TRUE)

# remove missing values and filter to recent monitor locations 
location_complete <- location_data[complete.cases(location_data$geo_lat, location_data$geo_lon), ] %>%
  filter(date > as.Date("2024-03-01"))

# Get unique combinations for each device
monitor_locations <- location_complete %>%
  group_by(monitor) %>%
  distinct(geo_lat, geo_lon) %>%
  
  # ADJUSTMENTS (ASK DJ TO CONFIRM) DUE TO ERRORS IN LONGITUDE
  mutate(geo_lon = case_when(geo_lon == -173058.0000 ~ -1.73058,
                             geo_lon == 1.5990 ~ -1.5990,
                             TRUE ~ geo_lon)) %>%
  filter(geo_lat != 8.05630)

# create spatial feature dataset of monitor points
monitor_points <- st_as_sf(monitor_locations, coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))



# LOAD IN THE COUNTRY AND REGION MAP DATA ----

country <- st_read(here("gha_admbnda_gss_20210308_SHP", "gha_admbnda_adm0_gss_20210308.shp"), quiet = TRUE)

regions <- st_read(here("gha_admbnda_gss_20210308_SHP", "gha_admbnda_adm1_gss_20210308.shp"), quiet = TRUE) %>%
  rename(region = ADM1_EN)

bono_east <- regions %>% filter(region == "Bono East")

# just the lat/lon for kintampo
kintampo_sf <- st_as_sf(data.frame(
  location = "Kintampo",
  geo_lon = -1.7296,
  geo_lat = 8.0593
), coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))


# LOAD IN THE ROADS DATA ----

# Load roads data and set CRS (assuming it's EPSG:4326)
roads <- st_read(here("hotosm_gha_roads_lines_shp", "hotosm_gha_roads_lines_shp.shp"), quiet = TRUE)
st_crs(roads) <- 4326


# Define the bounding box
bounding_box <- st_bbox(c(xmin = -2.2, ymin = 7.6, xmax = -1.3, ymax = 8.8), crs = st_crs(4326))

# Create a bounding box as an sf object
bbox_sf <- st_as_sfc(bounding_box)

# Filter the roads dataset to include only those within the bounding box
roads_filtered <- st_intersection(roads, bbox_sf)
```

```{r pm1 data, echo=FALSE, message=FALSE, warning=FALSE}
# LOAD POLLUTION DATA ----

# Define the pollutants of interest
pollutants <- c("pm1", "pm10", "pm25")

# Define the list to store results
results <- list()

# Load and summarize the data for each pollutant
for (pollutant in pollutants) {
  load_pollution_datasets(pollutant)
  
  colocation_data <- get(paste0(pollutant, "_colocation"))
  community_data <- get(paste0(pollutant, "_community"))
  
  colocation_summary <- summarize_data(colocation_data, pollutant)
  community_summary <- summarize_data(community_data, pollutant)
  
  results[[paste0(pollutant, "_colocation_hourly")]] <- colocation_summary$hourly
  results[[paste0(pollutant, "_colocation_daily")]] <- colocation_summary$daily
  results[[paste0(pollutant, "_community_hourly")]] <- community_summary$hourly
  results[[paste0(pollutant, "_community_daily")]] <- community_summary$daily
}

# Access the summarized results
pm1_colocation_hourly <- results$pm1_colocation_hourly
pm1_colocation_daily <- results$pm1_colocation_daily
pm10_colocation_hourly <- results$pm10_colocation_hourly
pm10_colocation_daily <- results$pm10_colocation_daily
pm25_colocation_hourly <- results$pm25_colocation_hourly
pm25_colocation_daily <- results$pm25_colocation_daily
pm1_community_hourly <- results$pm1_community_hourly
pm1_community_daily <- results$pm1_community_daily
pm10_community_hourly <- results$pm10_community_hourly
pm10_community_daily <- results$pm10_community_daily
pm25_community_hourly <- results$pm25_community_hourly
pm25_community_daily <- results$pm25_community_daily
```


## Monitor Locations

```{r monitor locations, echo=FALSE, message=FALSE, warning=FALSE}
# Define the bounding box coordinates
bbox_coords <- matrix(c(-2.2, 7.6, -2.2, 8.8, -1.3, 8.8, -1.3, 7.6, -2.2, 7.6), ncol = 2, byrow = TRUE)
bbox_polygon <- st_polygon(list(bbox_coords))
bbox_sf <- st_sfc(bbox_polygon, crs = st_crs(4326))

# Plot the map with the bounding box
ggplot() +
  # Add Ghana regions
  geom_sf(data = regions, fill = ifelse(regions$region == "Bono East", "#f5e493", "lightblue"), color = "black", alpha = 0.5) +
  # Add monitor points with transparency
  geom_sf(data = monitor_points, aes(geometry = geometry), color = "red", alpha = 0.5, size = 2) +
  # Add bounding box
  geom_sf(data = bbox_sf, fill = NA, color = "blue", lwd = 0.5, linetype = "solid") +
  # Add Ghana country boundary
  geom_sf(data = country, fill = NA, color = "black", size = 1) +
  labs(title = "Monitor Locations in Ghana") +
  theme_bw()


# Plot the zoomed-in map
ggplot() +
  # Add Ghana regions within the bounding box
  geom_sf(data = regions, fill = ifelse(regions$region == "Bono East", "#f5e493", "lightblue"), color = "black", alpha = 0.5) +
  # Add monitor points with transparency within the bounding box
  geom_sf(data = monitor_points, aes(geometry = geometry), color = "red", alpha = 0.5, size = 5) +
  # Add Kintampo marker
  geom_sf(data = kintampo_sf, aes(geometry = geometry), shape = 20, size = 3, color = "black") +
  # Add annotation text
  annotate("text", x = -1.73, y = 8.09, label = "KHRC", color = "black", size = 5) +
  # Zoom in to the bounding box
  coord_sf(xlim = c(-2.2, -1.3), ylim = c(7.6, 8.8), expand = FALSE) +
  labs(title = "Monitor Locations (Zoomed-In)",
       x = "", 
       y = "") +
  theme_bw()
```


# Summarizing Missingness

## Colocation Missingness

```{r colocation missingness, echo=FALSE, message=FALSE, warning=FALSE}
# THE MISSING DATA APPEARS TO BE CONSISTENT ACCROSS POLLUTANTS, SO USING PM 1 TO IDENTIFY MISSING VALUES 

# calculate total missingness across all of the monitors and the entire time range of interest 
overall_missingness <- mean(is.na(pm1_colocation$pm1)) * 100

# daily missingness  
daily_missingness <- pm1_colocation %>% 
  group_by(date) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  
  filter(date > as.Date("2023-08-15") & date < as.Date("2023-09-21"))

# hourly missingingness
hourly_missingness <- pm1_colocation %>% 
  group_by(hour) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100)

#monitor missingness
monitor_missingness <- pm1_colocation %>% 
  group_by(monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  mutate(monitor = fct_reorder(monitor, -missing_rate))



## DAILY MISSING DATA PERCENTAGE ----

#aggregated across monitors 
ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  geom_line() +
  labs(title = "Daily Missing Data Rate Over Time During Monitor Colocation", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")


ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  stat_smooth(span = 0.5) +
  labs(title = "Daily Missing Data Rate Over Time During Monitor Colocation", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")

  


## TOTAL MISSING DATA FOR EACH MONITOR ----

ggplot(monitor_missingness, aes(x = monitor, y = missing_rate)) +
  geom_bar(stat = "identity") +
  labs(title = "Missing Data Rate by Monitor During Colocation", x = "Monitor", y = "Missing Data Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 


# MISSING DATA PERCENTAGE FOR EACH HOUR OF THE DAY

#aggregated by monitor 
ggplot(hourly_missingness, aes(x = hour, y = missing_rate)) +
  geom_line() +
  labs(title = "Hourly Missing Data Rate During Monitor Colocation", x = "Hour of the Day", y = "Missing Data Rate (%)") +
  theme_minimal()

#facet wrap for each monitor 
pm1_colocation %>% 
  group_by(hour, monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  ggplot(aes(x = hour, y = missing_rate)) +
  geom_line() +
  facet_wrap(~monitor) +
  labs(y = "Missing data rate (%)",
       x = "Hour of the Day",
       title = "Hourly Missing Data Rate for Each Monitor During Colocation") +
  theme_bw()



## HEATMAP OF MISSINGNESS PER DAY FOR EACH MONITOR ----
pm1_colocation_with_week <- pm1_colocation %>%
  mutate(week = floor_date(date, "week")) # Extract the week


daily_na <- pm1_colocation_with_week %>%
  group_by(monitor, date) %>%
  summarize(na_percent = sum(is.na(pm1)) / n() * 100) %>%
  ungroup() %>%
  mutate(week = floor_date(date, "week"),  # Extract the week again for plotting
         day_of_week = factor(weekdays(date), 
                              levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")))  # Reorder days of the week
```

```{r colocation missingness heatmap, fig.height=12, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(daily_na, aes(x = week, y = day_of_week, fill = na_percent)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen", na.value = "white") +
  labs(title = "Percentage of Missing PM1 Data by Day During Colocation",
       x = "Week",
       y = "Day of Week",
       fill = "NA Percent") +
  scale_y_discrete(limits = rev(levels(daily_na$day_of_week)),  # Reverse the order to have Sunday at the top
                   breaks = c("Sunday", "Saturday")) +    # Label only specific days
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ monitor, scales = "free_x", ncol = 5)
```


## Community Missingness

```{r missing data, echo=FALSE, message=FALSE, warning=FALSE}
# calculate total missingness across all of the monitors and the entire time range of interest 
overall_missingness <- mean(is.na(pm1_community$pm1)) * 100

# daily missingness  
daily_missingness <- pm1_community %>% 
  group_by(date) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  
  filter(date > as.Date("2023-09-25") & date < as.Date("2024-06-11"))

# hourly missingingness
hourly_missingness <- pm1_community %>% 
  group_by(hour) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100)

#monitor missingness
monitor_missingness <- pm1_community %>% 
  group_by(monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  mutate(monitor = fct_reorder(monitor, -missing_rate))



## DAILY MISSING DATA PERCENTAGE ----

#aggregated across monitors 
ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  geom_line() +
  labs(title = "Daily Missing Data Rate Over Time", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")


ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  stat_smooth(span = 0.5) +
  labs(title = "Daily Missing Data Rate Over Time", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")

  


## TOTAL MISSING DATA FOR EACH MONITOR ----

ggplot(monitor_missingness, aes(x = monitor, y = missing_rate)) +
  geom_bar(stat = "identity") +
  labs(title = "Missing Data Rate by Monitor", x = "Monitor", y = "Missing Data Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 


# MISSING DATA PERCENTAGE FOR EACH HOUR OF THE DAY

#aggregated by monitor 
ggplot(hourly_missingness, aes(x = hour, y = missing_rate)) +
  geom_line() +
  labs(title = "Hourly Missing Data Rate", x = "Hour of the Day", y = "Missing Data Rate (%)") +
  theme_minimal()

#facet wrap for each monitor 
pm1_community %>% 
  group_by(hour, monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  ggplot(aes(x = hour, y = missing_rate)) +
  geom_line() +
  facet_wrap(~monitor) +
  theme_bw() +
  labs(title = "Hourly Missing Data Rate for Each Monitor During Colocation", x = "Hour of the Day", y = "Missing Data Rate (%)") +
  theme_minimal()


# MAP OF MONITOR MISSINGNESS BY LOCATION ----
missing_monitor_location <- left_join(monitor_missingness, monitor_points)

ggplot() +
  # Add Ghana regions within the bounding box
  geom_sf(data = regions, fill = ifelse(regions$region == "Bono East", "#f5e493", "lightblue"), color = "black", alpha = 0.5) +
  
  # Add monitor points with transparency within the bounding box
  geom_sf(data = missing_monitor_location, aes(geometry = geometry, color = missing_rate), alpha = 0.7, size = 5) +

  # Zoom in to the bounding box
  coord_sf(xlim = c(-2.2, -1.3), ylim = c(7.6, 8.8), expand = FALSE) +
  
  # Customize
  labs(title = "Monitor Missing Data and Location",
       x = "", 
       y = "") +
  theme_bw() +
  scale_color_gradient(low = "#0540a1", high = "#eb4c2d", name = "Missing Rate (%)")



## HEATMAP OF MISSINGNESS PER DAY FOR EACH MONITOR ----
pm1_community_with_week <- pm1_community %>%
  mutate(week = floor_date(date, "week")) # Extract the week


daily_na <- pm1_community_with_week %>%
  group_by(monitor, date) %>%
  summarize(na_percent = sum(is.na(pm1)) / n() * 100) %>%
  ungroup() %>%
  mutate(week = floor_date(date, "week"),  # Extract the week again for plotting
         day_of_week = factor(weekdays(date), 
                              levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")))  # Reorder days of the week
```

```{r missingness heat map, fig.height=16, fig.width=9, echo=FALSE, message=FALSE, warning=FALSE}

ggplot(daily_na, aes(x = week, y = day_of_week, fill = na_percent)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen", na.value = "white") +
  labs(title = "Percentage of Missing PM1 Data by Day",
       x = "Week",
       y = "Day of Week",
       fill = "NA Percent") +
  scale_y_discrete(limits = rev(levels(daily_na$day_of_week)),  # Reverse the order to have Sunday at the top
                   breaks = c("Sunday", "Saturday")) +    # Label only specific days
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ monitor, scales = "free_x", ncol = 5)
```



# Pollutant Trends

## PM 2.5

### Colocation 

#### Data Quality Check: Comparing PM 2.5 From Individual Monitors to Fleet Average

```{r colocation monitor fleet avg, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm25_colocation_hourly, "pm25", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm25_colocation_daily, "pm25", "daily")

```

#### PM 2.5 Trend Heatmap

```{r colocation pm1 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm25_colocation_hourly, "pm25")
```

### Community Deployment

#### Checking Individual Monitor to Fleet Average

```{r monitor vs fleet avg, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm25_community_hourly, "pm25", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm25_community_daily, "pm25", "daily")
```

#### PM 2.5 Trend Heatmap

```{r pm1 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm25_community_hourly, "pm25")
```



#### Spatial Correlation

```{r spatial correlation, echo=FALSE, message=FALSE, warning=FALSE}
generate_spatial_pollution_map(pm25_community, "pm25", missing_monitor_location)
```

#### Calculate Moran I for Spatial Correlation

```{r moran i, echo=FALSE, message=FALSE, warning=FALSE}
calculate_moran_i(pm25_community, "pm25", missing_monitor_location)
```

**Interpretation of Moran I Statistic**

-   -1: The variable of interest is perfectly dispersed

-   0: The variable of interest is randomly dispersed

-   1: The variable of interest is perfectly clustered together

#### Including proximity to road

```{r road, echo=FALSE, message=FALSE, warning=FALSE}

monitor_sf_road_dist <- prep_monitor_road_data(pm25_community, "pm25", missing_monitor_location, roads)

generate_spatial_pollution_road_map(monitor_sf_road_dist, roads_filtered, "pm25")

pm25_regression_results <- regress_polutant_road(monitor_sf_road_dist, "pm25")

print(pm25_regression_results$plot)
print(pm25_regression_results$summary_table)

```









## Grand Average plots 

```{r}
ghana_pm1 %>%
  group_by(date, monitor) %>%
  summarize(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1, group = monitor)) +
  geom_line(color = "black", alpha = 0.2) +
  theme_minimal() +
  labs(y = "Mean PM 1",
       title = "Average PM 1 Accross All Devices")

ghana_pm1 %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(monitor, date) %>%
  summarise(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1, group = monitor)) +
  geom_line(color = "black", alpha = 0.4) +
  theme_minimal() +
  labs(y = "Mean PM 1 ",
       title = "Daily Average PM 1 for Each Monitor During Primary Cooking Hours (3-7)") 


ghana_pm1 %>%
  group_by(date) %>%
  summarize(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 1",
       title = "Average PM 1 Accross All Devices")

ghana_pm1 %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(date) %>%
  summarize(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 1",
       title = "Mean PM 1 Accross All Devices During Cooking Hours (3-7)")



daily_pollutants <- left_join(pm1_community_daily, pm25_community_daily) %>% 
  left_join(pm10_community_daily)

daily_pollutants_long <- daily_pollutants %>%
  group_by(date) %>%
  summarise('Mean PM 1' = mean(mean_pm1, na.rm = TRUE),
            'Mean PM 2.5' = mean(mean_pm25, na.rm = TRUE),
            'Mean PM 10' = mean(mean_pm10, na.rm = TRUE)) %>%
  ungroup() %>%
  pivot_longer(cols = c("Mean PM 1", "Mean PM 2.5", "Mean PM 10"), names_to = "pollutant", values_to = "measurement")

# Convert the 'pollutant' column to a factor with the desired order
daily_pollutants_long$pollutant <- factor(daily_pollutants_long$pollutant, levels = c("Mean PM 1", "Mean PM 2.5", "Mean PM 10"))

daily_pollutants_long %>%
  ggplot(aes(x = date, y = measurement)) +
  geom_line() +
  theme_bw() +
  labs(x = "Date",
       y = "Pollutant Measurement",
       title = "Average Daily Particulate Matter Levels Across All Monitors") +
  facet_grid(pollutant ~ ., scales = "free_y")


daily_pollutants_long %>%
  ggplot(aes(x = date, y = measurement)) +
  geom_smooth() +
  theme_bw() +
  labs(x = "Date",
       y = "Pollutant Measurement",
       title = "Average Daily Particulate Matter Levels Across All Monitors") +
  facet_grid(pollutant ~ ., scales = "free_y")
```


