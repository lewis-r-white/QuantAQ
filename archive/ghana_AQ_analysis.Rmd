---
title: "Ghana Air Quality Analysis"
output: 
  html_document:
    toc: true
    theme: united
date: "2024-06-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
### load packages 
library(here) 
library(lubridate) 
library(tictoc)
library(DT)
library(purrr)
library(tidyverse)
library(data.table)
library(sf)
library(viridis)
library(knitr)
library(modelsummary)
library(spdep)
library(gstat)
library(units) 
library(gridExtra)

library(broom)
library(Metrics)
library(kableExtra)

```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Source in functions

# source in function that loads each pollution dataset separately to keep data small and prevent R crashes 
source(here("src", "load_pollution_datasets.R"))

# source function that aggregates data by time scale of interest (hourly, daily)
source(here("src", "summarize_pollution_times.R"))

# Source function that creates fleet average vs monitor pollutant reading plot
source(here("src", "compare_fleet_avg_monitor.R"))

# Source function that creates heatmap of pollutant readings
source(here("src", "generate_heatmap.R"))

# Source function to make map of pollution values at each monitor location
source(here("src", "generate_spatial_pollution_map.R"))

# source function to calculate moran i 
source(here("src", "calculate_moran_i.R"))

# source function to prepare data for road regression analysis and plotting
source(here("src", "prep_monitor_road_data.R"))

# source function to plot map of pollutant levels by location with roads 
source(here("src", "generate_spatial_pollution_road_map.R"))

# source function to run regression analysis on pollutant / distance to road
source(here("src", "regress_pollutant_road.R"))

# source function to apply regressions when comparing monitor to fleet average
source(here("src", "compare_fleet_regression.R"))

# source functions to merge in the SD card data for cases when server data is missing 
source(here("src", "merge_sd_data.R"))
source(here("src", "process_multiple_pollutants.R"))

#source functions to create plot that compares individual monitor to golden monitor
source(here("src", "compare_gas_to_reference_functions.R"))

#source functions to create plot that compares individual monitor to golden monitor
source(here("src", "calc_gas_regressions.R"))
```



```{r location data, echo=FALSE, message=FALSE, warning=FALSE}
#LOAD LOCATION DATA ----
monitor_community_info <- read_csv(here("data", "monitor_community_info.csv"))

# create spatial feature dataset of monitor points
#monitor_points <- st_as_sf(monitor_community_info, coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))


monitor_points <- monitor_community_info %>%
  st_as_sf(coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))


# LOAD IN THE COUNTRY AND REGION MAP DATA ----

country <- st_read(here("data", "spatial", "ghana_boundaries_shp", "gha_admbnda_adm0_gss_20210308.shp"), quiet = TRUE)

regions <- st_read(here("data", "spatial", "ghana_boundaries_shp",  "gha_admbnda_adm1_gss_20210308.shp"), quiet = TRUE) %>%
  rename(region = ADM1_EN)

bono_east <- regions %>% filter(region == "Bono East")


## SPECIFIC TOWN MARKERS ----

# just the lat/lon for kintampo
kintampo_sf <- st_as_sf(data.frame(
  location = "Kintampo",
  geo_lon = -1.7296,
  geo_lat = 8.0593
), coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))

# Dwenewoho
dwenewoho_sf <- st_as_sf(data.frame(
  location = "dwenewoho",
  geo_lon = -1.8325,
  geo_lat = 7.7403
), coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))


# New Longoro
new_longoro_sf <- st_as_sf(data.frame(
  location = "New Longoro",
  geo_lon = -2.02953,
  geo_lat = 8.14399
), coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))

# Apesika
apesika_sf <- st_as_sf(data.frame(
  location = "Apesika",
  geo_lon = -1.5453,
  geo_lat = 7.99838
), coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))

# Kurawura Akura
kurawura_akura_sf <- st_as_sf(data.frame(
  location = "Kurawura Akura",
  geo_lon = -1.4684,
  geo_lat = 8.7380
), coords = c("geo_lon", "geo_lat"), crs = st_crs(4326))


# LOAD IN THE ROADS DATA ----

# Load roads data and set CRS (assuming it's EPSG:4326)
roads <- st_read(here("data", "spatial", "ghana_roads_shp", "hotosm_gha_roads_lines_shp.shp"), quiet = TRUE)
st_crs(roads) <- 4326

#Filter the roads to only bono east
roads_filtered <- st_intersection(roads, bono_east)
```


## Monitor Locations

```{r plot monitor locations, echo=FALSE, message=FALSE, warning=FALSE}
# Define the bounding box coordinates
bbox_coords <- matrix(c(-2.2, 7.6, -2.2, 8.8, -1.3, 8.8, -1.3, 7.6, -2.2, 7.6), ncol = 2, byrow = TRUE)
bbox_polygon <- st_polygon(list(bbox_coords))
bbox_sf <- st_sfc(bbox_polygon, crs = st_crs(4326))

# Plot the map with the bounding box
ggplot() +
  # Add Ghana regions
  geom_sf(data = regions, fill = ifelse(regions$region == "Bono East", "#f5e493", "#dadbe0"), color = "black", alpha = 0.5) +
  # Add monitor points with transparency
  geom_sf(data = monitor_points, aes(geometry = geometry), color = "red", alpha = 0.5, size = 2) +
  # Add bounding box
  geom_sf(data = bbox_sf, fill = NA, color = "blue", lwd = 0.5, linetype = "solid") +
  # Add Ghana country boundary
  geom_sf(data = country, fill = NA, color = "black", size = 1) +
  #labs(title = "Monitor Locations in Ghana") +
  theme_bw() +
  theme(
    axis.text = element_text(size = 11), # Increase axis text size
    axis.ticks = element_line(size = 1), # Increase tick mark size
    plot.title = element_text(size = 16) 
  )


ggplot() +
  # Add Ghana regions within the bounding box
  geom_sf(data = regions, fill = ifelse(regions$region == "Bono East", "#ffe493", "#dadbe0"), color = "black", alpha = 0.5) +
  # Add monitor points with transparency within the bounding box
  geom_sf(data = monitor_points %>%
          mutate(geometry = st_jitter(geometry, amount = 0.001)), 
        aes(color = monitor_type), alpha = 0.6, size = 5) +
  
  # Add Kintampo marker
  geom_sf(data = kintampo_sf, aes(geometry = geometry), shape = 20, size = 3, color = "black") +
  # Add Dwenewoho marker
  geom_sf(data = dwenewoho_sf, aes(geometry = geometry), shape = 20, size = 3, color = "black") +
  # Add new longoro marker
  geom_sf(data = new_longoro_sf, aes(geometry = geometry), shape = 20, size = 3, color = "black") +
  # Add apesika marker
  geom_sf(data = apesika_sf, aes(geometry = geometry), shape = 20, size = 3, color = "black") +
  # Add kurawura akura marker
  geom_sf(data = kurawura_akura_sf, aes(geometry = geometry), shape = 20, size = 3, color = "black") +
  
  # Add Kintamp annotation text
  annotate("text", x = -1.73, y = 8.10, label = "Kintampo", color = "black", size = 5) +
  # Add Dwenewoho annotation text
  annotate("text", x = -1.69, y = 7.74, label = "Dwenewoho", color = "black", size = 5) +
  # Add new longoro annotation text
  annotate("text", x = -2.047, y = 8.214, label = "New Longoro", color = "black", size = 5) +
  # Add apesika annotation text
  annotate("text", x = -1.459, y = 7.96, label = "Apesika", color = "black", size = 5) +
  # Add atta akura annotation text
  annotate("text", x = -1.65, y = 8.75, label = "Kurawura Akura", color = "black", size = 5) +
  
  # Zoom in to the bounding box
  coord_sf(xlim = c(-2.2, -1.3), ylim = c(7.6, 8.8), expand = FALSE) +
  labs(x = "", 
       y = "",
       color = "Monitor Type") +
  theme_bw() +
  theme(
    axis.text = element_text(size = 11), # Increase axis text size
    axis.ticks = element_line(size = 0.5), # Increase tick mark size
    plot.title = element_text(size = 16), # Increase title size
    legend.text = element_text(size = 10), # Increase legend text size
    legend.title = element_text(size = 12) # Increase legend title size
  )
```


## Load corrected pollution data and create summaries 

```{r}
# LOAD CORRECTED FULL POLLUTION DATA ----
pm1_corrected <- readRDS(here("data", "pm", "final", "pm1corrected_20231024-20240816.rds"))
pm25_corrected <- readRDS(here("data", "pm", "final", "pm25corrected_20231024-20240816.rds"))
pm10_corrected <- readRDS(here("data", "pm", "final", "pm10corrected_20231024-20240816.rds"))



## LOAD CORRECTED SUMMARIZED POLLUTION DATA ----
pm1_community_hourly <- readRDS(here("data", "pm", "summarized", "pm1_community_hourly_20231024-20240816.rds"))
pm1_community_daily <- readRDS(here("data", "pm", "summarized", "pm1_community_daily_20231024-20240816.rds"))

pm25_community_hourly <- readRDS(here("data", "pm", "summarized", "pm25_community_hourly_20231024-20240816.rds"))
pm25_community_daily <- readRDS(here("data", "pm", "summarized", "pm25_community_hourly_20231024-20240816.rds"))

pm10_community_hourly <- readRDS(here("data", "pm", "summarized", "pm10_community_hourly_20231024-20240816.rds"))
pm10_community_daily <- readRDS(here("data", "pm", "summarized", "pm10_community_hourly_20231024-20240816.rds"))

```



# Summarizing Missingness of Server Data

## Colocation Missingness

```{r colocation missingness, echo=FALSE, message=FALSE, warning=FALSE}
# THE MISSING DATA APPEARS TO BE CONSISTENT ACCROSS POLLUTANTS, SO USING PM 1 TO IDENTIFY MISSING VALUES 
pm1_colocation <- read_rds(here("data", "pm", "colocation", "pm1_colocation_merged.rds"))
pm10_colocation <- read_rds(here("data", "pm", "colocation", "pm10_colocation_merged.rds"))
pm25_colocation <- read_rds(here("data", "pm", "colocation", "pm25_colocation_merged.rds"))

summarized_pm1_colocation <- summarize_pollution_times(pm1_colocation, "pm1")
summarized_pm10_colocation <- summarize_pollution_times(pm10_colocation, "pm10")
summarized_pm25_colocation <- summarize_pollution_times(pm25_colocation, "pm25")


pm1_colocation_hourly <- summarized_pm1_colocation$hourly
pm1_colocation_daily <- summarized_pm1_colocation$daily

pm10_colocation_hourly <- summarized_pm10_colocation$hourly
pm10_colocation_daily <- summarized_pm10_colocation$daily

pm25_colocation_hourly <- summarized_pm25_colocation$hourly
pm25_colocation_daily <- summarized_pm25_colocation$daily



# calculate total missingness across all of the monitors and the entire time range of interest 
overall_missingness <- mean(is.na(pm1_colocation$pm1)) * 100

# daily missingness  
daily_missingness <- pm1_colocation %>% 
  group_by(date) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  
  filter(date > as.Date("2023-08-15") & date < as.Date("2023-09-21"))

# hourly missingingness
hourly_missingness <- pm1_colocation %>% 
  group_by(hour) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100)

#monitor missingness
monitor_missingness <- pm1_colocation %>% 
  group_by(monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  mutate(monitor = fct_reorder(monitor, -missing_rate))



## DAILY MISSING DATA PERCENTAGE ----

#aggregated across monitors 
ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  geom_line() +
  labs(title = "Daily Missing Data Rate Over Time During Monitor Colocation", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")

#aggregated across monitors, smoothed
ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  stat_smooth(span = 0.5) +
  labs(title = "Daily Missing Data Rate Over Time During Monitor Colocation", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")

  


## TOTAL MISSING DATA FOR EACH MONITOR ----

ggplot(monitor_missingness, aes(x = monitor, y = missing_rate)) +
  geom_bar(stat = "identity") +
  labs(title = "Missing Data Rate by Monitor During Colocation", x = "Monitor", y = "Missing Data Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 


# MISSING DATA PERCENTAGE FOR EACH HOUR OF THE DAY

#aggregated by monitor 
ggplot(hourly_missingness, aes(x = hour, y = missing_rate)) +
  geom_line() +
  labs(title = "Hourly Missing Data Rate During Monitor Colocation", x = "Hour of the Day", y = "Missing Data Rate (%)") +
  theme_minimal()

#facet wrap for each monitor 
pm1_colocation %>% 
  group_by(hour, monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  ggplot(aes(x = hour, y = missing_rate)) +
  geom_line() +
  facet_wrap(~monitor) +
  labs(y = "Missing data rate (%)",
       x = "Hour of the Day",
       title = "Hourly Missing Data Rate for Each Monitor During Colocation") +
  theme_bw()



## HEATMAP OF MISSINGNESS PER DAY FOR EACH MONITOR ----
pm1_colocation_with_week <- pm1_colocation %>%
  mutate(week = floor_date(date, "week")) # Extract the week


daily_na <- pm1_colocation_with_week %>%
  group_by(monitor, date) %>%
  summarize(na_percent = sum(is.na(pm1)) / n() * 100) %>%
  ungroup() %>%
  mutate(week = floor_date(date, "week"),  # Extract the week again for plotting
         day_of_week = factor(weekdays(date), 
                              levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")))  # Reorder days of the week
```

```{r colocation missingness heatmap, fig.height=12, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(daily_na, aes(x = week, y = day_of_week, fill = na_percent)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen", na.value = "white") +
  labs(title = "Percentage of Missing PM1 Data by Day During Colocation",
       x = "Week",
       y = "Day of Week",
       fill = "NA Percent") +
  scale_y_discrete(limits = rev(levels(daily_na$day_of_week)),  # Reverse the order to have Sunday at the top
                   breaks = c("Sunday", "Saturday")) +    # Label only specific days
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ monitor, scales = "free_x", ncol = 5)
```


## Community Missingness

```{r missing data, echo=FALSE, message=FALSE, warning=FALSE}
# calculate total missingness across all of the monitors and the entire time range of interest 
overall_missingness <- mean(is.na(pm1_corrected$pm1)) * 100

# daily missingness  
daily_missingness <- pm1_corrected %>% 
  group_by(date) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  
  filter(date > as.Date("2023-09-25") & date < as.Date("2024-06-11"))

# hourly missingingness
hourly_missingness <- pm1_corrected %>% 
  group_by(hour) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100)

#monitor missingness
monitor_missingness <- pm1_corrected %>% 
  group_by(monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  mutate(monitor = fct_reorder(monitor, -missing_rate))



## DAILY MISSING DATA PERCENTAGE ----

#aggregated across monitors 
ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  geom_line() +
  labs(title = "Daily Missing Data Rate Over Time During Community Deployment", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")


ggplot(daily_missingness, aes(x = date, y = missing_rate)) +
  stat_smooth(span = 0.5) +
  labs(title = "Daily Missing Data Rate Over Time During Community Deployment", x = "Date", y = "Missing Data Rate (%)") +
  theme_minimal() +
  geom_hline(yintercept = overall_missingness, color = "red")

  


## TOTAL MISSING DATA FOR EACH MONITOR ----

ggplot(monitor_missingness, aes(x = monitor, y = missing_rate)) +
  geom_bar(stat = "identity") +
  labs(title = "Missing Data Rate by Monitor During Community Deployment", x = "Monitor", y = "Missing Data Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 


# MISSING DATA PERCENTAGE FOR EACH HOUR OF THE DAY

#aggregated by monitor 
ggplot(hourly_missingness, aes(x = hour, y = missing_rate)) +
  geom_line() +
  labs(title = "Hourly Missing Data Rate During Community Deployment", x = "Hour of the Day", y = "Missing Data Rate (%)") +
  theme_minimal()

#facet wrap for each monitor 
pm1_corrected %>% 
  group_by(hour, monitor) %>% 
  summarise(missing_rate = mean(is.na(pm1)) * 100) %>%
  ggplot(aes(x = hour, y = missing_rate)) +
  geom_line() +
  facet_wrap(~monitor) +
  theme_bw() +
  labs(title = "Hourly Missing Data Rate for Each Monitor During Community Deployment", x = "Hour of the Day", y = "Missing Data Rate (%)") +
  theme_minimal()


# MAP OF MONITOR MISSINGNESS BY LOCATION ----


missing_monitor_location <- left_join(monitor_missingness, monitor_points)

ggplot() +
  # Add Ghana regions within the bounding box
  geom_sf(data = regions, fill = ifelse(regions$region == "Bono East", "#f5e493", "lightblue"), color = "black", alpha = 0.5) +
  
  # Add monitor points with transparency within the bounding box
  geom_sf(data = missing_monitor_location, aes(geometry = geometry, color = missing_rate), alpha = 0.7, size = 5) +

  # Zoom in to the bounding box
  coord_sf(xlim = c(-2.2, -1.3), ylim = c(7.6, 8.8), expand = FALSE) +
  
  # Customize
  labs(title = "Monitor Missing Data and Location",
       x = "", 
       y = "") +
  theme_bw() +
  scale_color_gradient(low = "#0540a1", high = "#eb4c2d", name = "Missing Rate (%)")
```

### Spatial Correlation of Missing Data 
```{r spatial missing data, echo=FALSE, message=FALSE, warning=FALSE}
# Convert to an sf object
missing_monitor_location <- st_as_sf(missing_monitor_location)

coords <- st_coordinates(missing_monitor_location)
nb <- knn2nb(knearneigh(coords, k = 5)) # k-nearest neighbors
listw <- nb2listw(nb, style = "W")
  
# Calculate Moran's I
moran_result <- moran.test(missing_monitor_location$missing_rate, listw)

# Extract relevant values directly
observed_value <- as.numeric(moran_result$estimate["Moran I statistic"])
expected_value <- as.numeric(moran_result$estimate["Expectation"])
variance <- as.numeric(moran_result$estimate["Variance"])
z_score <- as.numeric(moran_result$statistic)
p_value <- as.numeric(moran_result$p.value)

# Create the Moran's I results table
moran_table <- data.frame(
  Test = "Moran's I Statistic",
  `Observed Value` = observed_value,
  `Expected Value` = expected_value,
  `Variance` = variance,
  `Z-score` = z_score,
  `p-value` = p_value
)

moran_table
```

**Interpretation of Moran I Statistic**

-   -1: The variable of interest is perfectly dispersed

-   0: The variable of interest is randomly dispersed

-   1: The variable of interest is perfectly clustered together

```{r missingness heat map, fig.height=16, fig.width=9, echo=FALSE, message=FALSE, warning=FALSE}
## HEATMAP OF MISSINGNESS PER DAY FOR EACH MONITOR ----
pm1_corrected_with_week <- pm1_corrected %>%
  mutate(week = floor_date(date, "week")) # Extract the week


daily_na <- pm1_corrected_with_week %>%
  group_by(monitor, date) %>%
  summarize(na_percent = sum(is.na(pm1)) / n() * 100) %>%
  ungroup() %>%
  mutate(week = floor_date(date, "week"),  # Extract the week again for plotting
         day_of_week = factor(weekdays(date), 
                              levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")))  # Reorder days of the week

ggplot(daily_na, aes(x = week, y = day_of_week, fill = na_percent)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen", na.value = "white") +
  labs(title = "Percentage of Missing PM1 Data by Day During Community Deployment",
       x = "Week",
       y = "Day of Week",
       fill = "NA Percent") +
  scale_y_discrete(limits = rev(levels(daily_na$day_of_week)),  # Reverse the order to have Sunday at the top
                   breaks = c("Sunday", "Saturday")) +    # Label only specific days
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ monitor, scales = "free_x", ncol = 5)
```


# Pollutant Trends

## Grand Average plots 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
daily_pollutants <- left_join(pm1_community_daily, pm25_community_daily) %>% 
  left_join(pm10_community_daily)

daily_pollutants_long <- daily_pollutants %>%
  group_by(date) %>%
  summarise('Mean PM 1' = mean(mean_pm1, na.rm = TRUE),
            'Mean PM 2.5' = mean(mean_pm25, na.rm = TRUE),
            'Mean PM 10' = mean(mean_pm10, na.rm = TRUE)) %>%
  ungroup() %>%
  pivot_longer(cols = c("Mean PM 1", "Mean PM 2.5", "Mean PM 10"), names_to = "pollutant", values_to = "measurement")

# Convert the 'pollutant' column to a factor with the desired order
daily_pollutants_long$pollutant <- factor(daily_pollutants_long$pollutant, levels = c("Mean PM 1", "Mean PM 2.5", "Mean PM 10"))

daily_pollutants_long %>%
  ggplot(aes(x = date, y = measurement)) +
  geom_line() +
  theme_bw() +
  labs(x = "Date",
       y = "Pollutant Measurement",
       title = "Average Daily Particulate Matter Levels Across All Monitors") +
  facet_grid(pollutant ~ ., scales = "free_y")


daily_pollutants_long %>%
  ggplot(aes(x = date, y = measurement)) +
  geom_smooth() +
  theme_bw() +
  labs(x = "Date",
       y = "Pollutant Measurement",
       title = "Average Daily Particulate Matter Levels Across All Monitors") +
  facet_grid(pollutant ~ ., scales = "free_y")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
mod_sep_daily_pollutants_long <- daily_pollutants %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date) %>%
  summarize(across(where(is.numeric), list(mean = mean), na.rm = TRUE)) %>%
  ungroup() %>%
  rename("Mean PM 1" = mean_pm1_mean, 
         "Mean PM 2.5" = mean_pm25_mean,
         "Mean PM 10" = mean_pm10_mean) %>%
  
  pivot_longer(cols = c("Mean PM 1", "Mean PM 2.5", "Mean PM 10"), names_to = "pollutant", values_to = "measurement") %>%
  
  mutate(mod_pm = case_when(mod_pm == "FALSE" ~ "MOD Device",
                            mod_pm == "TRUE" ~ "MOD-PM Device"))
  

mod_sep_daily_pollutants_long$pollutant <- factor(mod_sep_daily_pollutants_long$pollutant, levels = c("Mean PM 1", "Mean PM 2.5", "Mean PM 10"))
  

mod_sep_daily_pollutants_long %>%
  ggplot(aes(x = date, y = measurement)) +
  geom_line() +
  theme_bw() +
  labs(x = "Date",
       y = "Pollutant Measurement",
       title = "Average Daily Particulate Matter Levels Across Monitors",
       subtitle = "Comparing MOD devices to MOD-PM devices") +
  facet_grid(pollutant ~ mod_pm, scales = "free_y")
```




```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary_data <- daily_pollutants %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date) %>%
  summarize(across(where(is.numeric), list(mean = mean), na.rm = TRUE), .groups = 'drop') %>%
  ungroup() %>%
  group_by(mod_pm, date) %>%
  summarize(mean_pm1 = mean(mean_pm1_mean, na.rm = TRUE),
            mean_pm25 = mean(mean_pm25_mean, na.rm = TRUE),
            mean_pm10 = mean(mean_pm10_mean, na.rm = TRUE), .groups = 'drop') %>%
  filter(mod_pm == TRUE)

# Calculate distribution statistics
distribution_stats <- summary_data %>%
  summarize(Statistic = c("Min", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max"),
            PM1 = round(c(min(mean_pm1, na.rm = TRUE),
                    quantile(mean_pm1, 0.25, na.rm = TRUE),
                    median(mean_pm1, na.rm = TRUE),
                    mean(mean_pm1, na.rm = TRUE),
                    quantile(mean_pm1, 0.75, na.rm = TRUE),
                    max(mean_pm1, na.rm = TRUE)), 2),
            PM25 = round(c(min(mean_pm25, na.rm = TRUE),
                     quantile(mean_pm25, 0.25, na.rm = TRUE),
                     median(mean_pm25, na.rm = TRUE),
                     mean(mean_pm25, na.rm = TRUE),
                     quantile(mean_pm25, 0.75, na.rm = TRUE),
                     max(mean_pm25, na.rm = TRUE)), 2),
            PM10 = round(c(min(mean_pm10, na.rm = TRUE),
                     quantile(mean_pm10, 0.25, na.rm = TRUE),
                     median(mean_pm10, na.rm = TRUE),
                     mean(mean_pm10, na.rm = TRUE),
                     quantile(mean_pm10, 0.75, na.rm = TRUE),
                     max(mean_pm10, na.rm = TRUE)), 2))

# Create the table using kable and kableExtra
kable(distribution_stats, format = "html", col.names = c("Statistic", "PM1", "PM2.5", "PM10")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE) %>%
  add_header_above(c(" " = 1, "MOD-PM Device Pollutant Daily Distribution" = 3)) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, bold = TRUE)






# Assuming you have your summary data in a dataframe called summary_data
summary_data <- daily_pollutants %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date) %>%
  summarize(across(where(is.numeric), list(mean = mean), na.rm = TRUE), .groups = 'drop') %>%
  ungroup() %>%
  group_by(mod_pm, date) %>%
  summarize(mean_pm1 = mean(mean_pm1_mean, na.rm = TRUE),
            mean_pm25 = mean(mean_pm25_mean, na.rm = TRUE),
            mean_pm10 = mean(mean_pm10_mean, na.rm = TRUE), .groups = 'drop') %>%
  filter(mod_pm == FALSE)

# Calculate distribution statistics
distribution_stats <- summary_data %>%
  summarize(Statistic = c("Min", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max"),
            PM1 = round(c(min(mean_pm1, na.rm = TRUE),
                    quantile(mean_pm1, 0.25, na.rm = TRUE),
                    median(mean_pm1, na.rm = TRUE),
                    mean(mean_pm1, na.rm = TRUE),
                    quantile(mean_pm1, 0.75, na.rm = TRUE),
                    max(mean_pm1, na.rm = TRUE)), 2),
            PM25 = round(c(min(mean_pm25, na.rm = TRUE),
                     quantile(mean_pm25, 0.25, na.rm = TRUE),
                     median(mean_pm25, na.rm = TRUE),
                     mean(mean_pm25, na.rm = TRUE),
                     quantile(mean_pm25, 0.75, na.rm = TRUE),
                     max(mean_pm25, na.rm = TRUE)), 2),
            PM10 = round(c(min(mean_pm10, na.rm = TRUE),
                     quantile(mean_pm10, 0.25, na.rm = TRUE),
                     median(mean_pm10, na.rm = TRUE),
                     mean(mean_pm10, na.rm = TRUE),
                     quantile(mean_pm10, 0.75, na.rm = TRUE),
                     max(mean_pm10, na.rm = TRUE)), 2))

# Create the table using kable and kableExtra
kable(distribution_stats, format = "html", col.names = c("Statistic", "PM1", "PM2.5", "PM10")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE) %>%
  add_header_above(c(" " = 1, "MOD Device Pollutant Daily Distribution" = 3)) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, bold = TRUE)
```







## PM 2.5 Colocation 

### Data Quality Check: Comparing PM 2.5 From Individual Monitors to Fleet Average

```{r colocation monitor fleet avg 25, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm25_colocation_hourly, "pm25", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm25_colocation_daily, "pm25", "daily")
```

#### PM 2.5 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm25_hourly_regression_data <- pm25_colocation_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm25))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm25_colocation_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm25))


pm25_colocation_regression_results <- apply_regression(pm25_hourly_regression_data, "mean_pm25", "fleet_average_pm25")

datatable(pm25_colocation_regression_results)
```

#### PM 2.5 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm25_daily_regression_data <- pm25_colocation_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm25))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm25_colocation_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm25))


pm25_colocation_regression_results <- apply_regression(pm25_daily_regression_data, "mean_pm25", "fleet_average_pm25")

datatable(pm25_colocation_regression_results)
```

### PM 2.5 Colocation MOD vs MOD-PM measures to check consistency

```{r, echo=FALSE, message=FALSE, warning=FALSE}
mod_pm_pm25 <- pm25_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm25, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == TRUE)

mod_pm25 <- pm25_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm25, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == FALSE)

# Extract the mean_hourly_pm vectors
MOD_PM_pm25_means <- mod_pm_pm25$mean_hourly_pm
MOD_pm25_means <- mod_pm25$mean_hourly_pm

# Perform t-test
t_test_result <- t.test(MOD_PM_pm25_means, MOD_pm25_means)

# Print the result
print(t_test_result)
```


### PM 2.5 Trend Heatmap

```{r colocation pm25 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm25_colocation_hourly, "pm25")
```

## PM 2.5 Community Deployment

### Checking Individual Monitor to Fleet Average

```{r monitor vs fleet avg 25, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm25_community_hourly, "pm25", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm25_community_daily, "pm25", "daily")
```

#### PM 2.5 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm25_hourly_regression_data <- pm25_community_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm25))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm25_community_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm25))


pm25_colocation_regression_results <- apply_regression(pm25_hourly_regression_data, "mean_pm25", "fleet_average_pm25")

datatable(pm25_colocation_regression_results)
```



### PM 2.5 Trends

```{r pm25 timelines, echo=FALSE, message=FALSE, warning=FALSE}
daily_pm25_all_devices <- pm25_corrected %>%
  group_by(date, monitor) %>%
  summarize(mean_pm25 = mean(pm25, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm25, group = monitor)) +
  geom_line(color = "black", alpha = 0.2) +
  theme_minimal() +
  labs(y = "Mean PM 2.5",
       title = "Average PM 2.5 Accross All Devices")

daily_cooktime_pm25_all_devices <- pm25_corrected %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(monitor, date) %>%
  summarise(mean_pm25 = mean(pm25, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm25, group = monitor)) +
  geom_line(color = "black", alpha = 0.4) +
  theme_minimal() +
  labs(y = "Mean PM 2.5",
       title = "Daily Average PM 2.5 for Each Monitor During Primary Cooking Hours (3-7)") 

grid.arrange(daily_pm25_all_devices, daily_cooktime_pm25_all_devices)

daily_pm25_timeline <- pm25_corrected %>%
  group_by(date) %>%
  summarize(mean_pm25 = mean(pm25, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm25)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 2.5",
       title = "Average PM 2.5 Accross All Devices")

daily_cooktime_pm25_timeline <- pm25_corrected %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(date) %>%
  summarize(mean_pm25 = mean(pm25, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm25)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 2.5",
       title = "Mean PM 2.5 Accross All Devices During Cooking Hours (3-7)")

grid.arrange(daily_pm25_timeline, daily_cooktime_pm25_timeline)
```

### PM 2.5 Heatmap

```{r pm25 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm25_community_hourly, "pm25")
```





### Spatial Correlation

```{r spatial correlation 25, echo=FALSE, message=FALSE, warning=FALSE}
generate_spatial_pollution_map(pm25_corrected, "pm25", missing_monitor_location)
```

### Calculate Moran I for Spatial Correlation

```{r moran i 25, echo=FALSE, message=FALSE, warning=FALSE}
calculate_moran_i(pm25_corrected, "pm25", missing_monitor_location)
```

**Interpretation of Moran I Statistic**

-   -1: The variable of interest is perfectly dispersed

-   0: The variable of interest is randomly dispersed

-   1: The variable of interest is perfectly clustered together

### Including proximity to road

```{r road 25, echo=FALSE, message=FALSE, warning=FALSE}
monitor_sf_road_dist <- prep_monitor_road_data(pm25_corrected, "pm25", missing_monitor_location, roads)

generate_spatial_pollution_road_map(monitor_sf_road_dist, roads_filtered, "pm25")

pm25_regression_results <- regress_polutant_road(monitor_sf_road_dist, "pm25")

pm25_regression_results$plot_no_type

pm25_regression_results$plot_with_type

pm25_regression_results$summary_table
```


## PM 1 Colocation 

### Data Quality Check: Comparing PM 1 From Individual Monitors to Fleet Average

```{r colocation monitor fleet avg 1, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm1_colocation_hourly, "pm1", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm1_colocation_daily, "pm1", "daily")
```

#### PM 1 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm1_hourly_regression_data <- pm1_colocation_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm1))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm1_colocation_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm1))


pm1_colocation_regression_results <- apply_regression(pm1_hourly_regression_data, "mean_pm1", "fleet_average_pm1")

datatable(pm1_colocation_regression_results)
```

#### PM 1 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm1_daily_regression_data <- pm1_colocation_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm1))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm1_colocation_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm1))


pm1_colocation_regression_results <- apply_regression(pm1_daily_regression_data, "mean_pm1", "fleet_average_pm1")

datatable(pm1_colocation_regression_results)
```

### PM 1 Colocation MOD vs MOD-PM measures to check consistency

```{r, echo=FALSE, message=FALSE, warning=FALSE}
mod_pm_pm1 <- pm1_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm1, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == TRUE)

mod_pm1 <- pm1_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm1, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == FALSE)

# Extract the mean_hourly_pm vectors
MOD_PM_hourly_pm1_means <- mod_pm_pm1$mean_hourly_pm
MOD_hourly_pm1_means <- mod_pm1$mean_hourly_pm

# Perform t-test
t_test_result <- t.test(MOD_PM_hourly_pm1_means, MOD_hourly_pm1_means)

# Print the result
print(t_test_result)
```



### PM 1 Trend Heatmap

```{r colocation pm1 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm1_colocation_hourly, "pm1")
```

## PM 1 Community Deployment

### Checking Individual Monitor to Fleet Average

```{r monitor vs fleet avg 1, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm1_community_hourly, "pm1", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm1_community_daily, "pm1", "daily")
```

#### PM 1 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm1_hourly_regression_data <- pm1_community_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm1))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm1_community_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm1))


pm1_colocation_regression_results <- apply_regression(pm1_hourly_regression_data, "mean_pm1", "fleet_average_pm1")

datatable(pm1_colocation_regression_results)
```

#### PM 1 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm1_daily_regression_data <- pm1_community_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm1))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm1_community_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm1))


pm1_colocation_regression_results <- apply_regression(pm1_daily_regression_data, "mean_pm1", "fleet_average_pm1")

datatable(pm1_colocation_regression_results)
```


### PM 1 Trends

```{r pm1 timelines, echo=FALSE, message=FALSE, warning=FALSE}
daily_pm1_all_devices <- pm1_corrected %>%
  group_by(date, monitor) %>%
  summarize(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1, group = monitor)) +
  geom_line(color = "black", alpha = 0.2) +
  theme_minimal() +
  labs(y = "Mean PM 1",
       title = "Average PM 1 Accross All Devices")

daily_cooktime_pm1_all_devices <- pm1_corrected %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(monitor, date) %>%
  summarise(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1, group = monitor)) +
  geom_line(color = "black", alpha = 0.4) +
  theme_minimal() +
  labs(y = "Mean PM 1 ",
       title = "Daily Average PM 1 for Each Monitor During Primary Cooking Hours (3-7)") 

grid.arrange(daily_pm1_all_devices, daily_cooktime_pm1_all_devices)

daily_pm1_timeline <- pm1_corrected %>%
  group_by(date) %>%
  summarize(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 1",
       title = "Average PM 1 Accross All Devices")

daily_cooktime_pm1_timeline <- pm1_corrected %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(date) %>%
  summarize(mean_pm1 = mean(pm1, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm1)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 1",
       title = "Mean PM 1 Accross All Devices During Cooking Hours (3-7)")

grid.arrange(daily_pm1_timeline, daily_cooktime_pm1_timeline)
```

### PM 1 Heatmap

```{r pm1 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm1_community_hourly, "pm1")
```


### Spatial Correlation

```{r spatial correlation 1, echo=FALSE, message=FALSE, warning=FALSE}
generate_spatial_pollution_map(pm1_corrected, "pm1", missing_monitor_location)
```

### Calculate Moran I for Spatial Correlation

```{r moran i 1, echo=FALSE, message=FALSE, warning=FALSE}
calculate_moran_i(pm1_corrected, "pm1", missing_monitor_location)
```

**Interpretation of Moran I Statistic**

-   -1: The variable of interest is perfectly dispersed

-   0: The variable of interest is randomly dispersed

-   1: The variable of interest is perfectly clustered together

### Including proximity to road

```{r road 1, echo=FALSE, message=FALSE, warning=FALSE}
monitor_sf_road_dist <- prep_monitor_road_data(pm1_corrected, "pm1", missing_monitor_location, roads)

generate_spatial_pollution_road_map(monitor_sf_road_dist, roads_filtered, "pm1")

pm1_regression_results <- regress_polutant_road(monitor_sf_road_dist, "pm1")

pm1_regression_results$plot_no_type

pm1_regression_results$plot_with_type

pm1_regression_results$summary_table
```




## PM 10 Colocation 

### Data Quality Check: Comparing PM 10 From Individual Monitors to Fleet Average

```{r colocation monitor fleet avg 10, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm10_colocation_hourly, "pm10", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm10_colocation_daily, "pm10", "daily")
```

#### PM 10 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_hourly_regression_data <- pm10_colocation_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_colocation_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_hourly_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```

#### PM 10 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_daily_regression_data <- pm10_colocation_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_colocation_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_daily_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```


### PM 10 Colocation MOD vs MOD-PM measures to check consistency

```{r, echo=FALSE, message=FALSE, warning=FALSE}
mod_pm_pm10 <- pm10_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm10, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == TRUE)

mod_pm10 <- pm10_colocation_hourly %>%
  mutate(mod_pm = str_detect(monitor, "MOD-PM")) %>%
  group_by(mod_pm, date, hour) %>%
  summarize(mean_hourly_pm = mean(mean_pm10, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(mod_pm == FALSE)

# Extract the mean_hourly_pm vectors
MOD_PM_pm10_means <- mod_pm_pm10$mean_hourly_pm
MOD_pm10_means <- mod_pm10$mean_hourly_pm

# Perform t-test
t_test_result <- t.test(MOD_PM_pm10_means, MOD_pm10_means)

# Print the result
print(t_test_result)
```



### PM 10 Trend Heatmap

```{r colocation pm10 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm10_colocation_hourly, "pm10")
```

## PM 10 Community Deployment

### Checking Individual Monitor to Fleet Average

```{r monitor vs fleet avg 10, fig.height=10, fig.width=7, echo=FALSE, message=FALSE, warning=FALSE}
# hourly comparison
compare_fleet_avg_monitor(pm10_community_hourly, "pm10", "hourly")

# Daily comparison
compare_fleet_avg_monitor(pm10_community_daily, "pm10", "daily")
```


#### PM 10 Hourly: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_hourly_regression_data <- pm10_community_hourly %>% 
  group_by(date, hour) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_community_hourly) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_hourly_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```

#### PM 10 Daily: Individual Monitor Regressed on Fleet Average
**Note: fleet average required at minimum 5 readings to be included in regression)**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
pm10_daily_regression_data <- pm10_community_daily %>% 
  group_by(date) %>% 
  summarize(offline_monitors = sum(is.na(mean_pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_community_daily) %>%
  
  filter(offline_monitors < 35) %>%
  
  filter(!is.na(mean_pm10))


pm10_colocation_regression_results <- apply_regression(pm10_daily_regression_data, "mean_pm10", "fleet_average_pm10")

datatable(pm10_colocation_regression_results)
```


### PM 10 Trends

```{r pm10 timeline, echo=FALSE, message=FALSE, warning=FALSE}
daily_pm10_all_devices <- pm10_corrected %>%
  group_by(date, monitor) %>%
  summarize(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10, group = monitor)) +
  geom_line(color = "black", alpha = .4) +
  theme_minimal() +
  labs(y = "Mean PM 10",
       title = "Average PM 10 Accross All Devices")

daily_cooktime_pm10_all_devices <- pm10_corrected %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(monitor, date) %>%
  summarise(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10, group = monitor)) +
  geom_line(color = "black", alpha = 0.4) +
  theme_minimal() +
  labs(y = "Mean PM 10 ",
       title = "Daily Average PM 10 for Each Monitor During Primary Cooking Hours (3-7)") 

grid.arrange(daily_pm10_all_devices, daily_cooktime_pm10_all_devices)

daily_pm10_timeline <- pm10_corrected %>%
  group_by(date) %>%
  summarize(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 10",
       title = "Average PM 10 Accross All Devices")

daily_cooktime_pm10_timeline <- pm10_corrected %>%
  filter(hour >= 15 & hour < 18) %>%
  group_by(date) %>%
  summarize(mean_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = mean_pm10)) +
  geom_line() +
  theme_minimal() +
  labs(y = "Mean PM 10",
       title = "Mean PM 10 Accross All Devices During Cooking Hours (3-7)")

grid.arrange(daily_pm10_timeline, daily_cooktime_pm10_timeline)
```

### PM 10 Trend Heatmap

```{r pm10 trends, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(pm10_community_hourly, "pm10")
```

### Spatial Correlation

```{r spatial correlation 10, echo=FALSE, message=FALSE, warning=FALSE}
generate_spatial_pollution_map(pm10_corrected, "pm10", missing_monitor_location)
```

### Calculate Moran I for Spatial Correlation

```{r moran i 10, echo=FALSE, message=FALSE, warning=FALSE}
calculate_moran_i(pm10_corrected, "pm10", missing_monitor_location)
```

**Interpretation of Moran I Statistic**

-   -1: The variable of interest is perfectly dispersed

-   0: The variable of interest is randomly dispersed

-   1: The variable of interest is perfectly clustered together

### Including proximity to road

```{r road 10, echo=FALSE, message=FALSE, warning=FALSE}
monitor_sf_road_dist <- prep_monitor_road_data(pm10_corrected, "pm10", missing_monitor_location, roads)

generate_spatial_pollution_road_map(monitor_sf_road_dist, roads_filtered, "pm10")

pm10_regression_results <- regress_polutant_road(monitor_sf_road_dist, "pm10")

pm10_regression_results$plot_no_type

pm10_regression_results$plot_with_type 

pm10_regression_results$summary_table
```
















# Gas Trends

```{r}
## LOAD GAS DATA ----

# load full gas data
gas_corrected_full <- readRDS(here("data", "gas", "final", "corrected_community_gas_20230926-20240816.rds"))

# load individual gas data summarized
co_community_hourly <- readRDS(here("data", "gas", "summarized", "co_community_hourly_20231024-20240816.rds"))
co_community_daily <- readRDS(here("data", "gas", "summarized", "co_community_daily_20231024-20240816.rds"))

no_community_hourly <- readRDS(here("data", "gas", "summarized", "no_community_hourly_20231024-20240816.rds"))
no_community_daily <- readRDS(here("data", "gas", "summarized", "no_community_daily_20231024-20240816.rds"))

no2_community_hourly <- readRDS(here("data", "gas", "summarized", "no2_community_hourly_20231024-20240816.rds"))
no2_community_daily <- readRDS(here("data", "gas", "summarized", "no2_community_daily_20231024-20240816.rds"))

o3_community_hourly <- readRDS(here("data", "gas", "summarized", "o3_community_hourly_20231024-20240816.rds"))
o3_community_daily <- readRDS(here("data", "gas", "summarized", "o3_community_daily_20231024-20240816.rds"))




colocation_gas <- read_rds(here("data", "gas", "colocation", "colocation_gas.rds"))

summarized_co_colocation <- summarize_pollution_times(colocation_gas, "co")
summarized_no_colocation <- summarize_pollution_times(colocation_gas, "no")
summarized_no2_colocation <- summarize_pollution_times(colocation_gas, "no2")
summarized_o3_colocation <- summarize_pollution_times(colocation_gas, "o3")

co_colocation_hourly <- summarized_co_colocation$hourly
co_colocation_daily <- summarized_co_colocation$daily

no_colocation_hourly <- summarized_no_colocation$hourly
no_colocation_daily <- summarized_no_colocation$daily

no2_colocation_hourly <- summarized_no2_colocation$hourly
no2_colocation_daily <- summarized_no2_colocation$daily

o3_colocation_hourly <- summarized_o3_colocation$hourly
o3_colocation_daily <- summarized_o3_colocation$daily
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot_daily_mean_pollutant <- function(data, pollutant_measurement, title = NULL) {
  pollutant_col <- sym(paste0("mean_", pollutant_measurement))
  
  ggplot(data, aes(x = date, y = !!pollutant_col)) +
    geom_line() +
    facet_wrap(~monitor, ncol = 2) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Rotate x-axis labels
    labs(x = "Date",
         y = paste("Daily Mean", toupper(pollutant_measurement)),
         title = title)
}

plot_co_col_time <- plot_daily_mean_pollutant(co_colocation_daily, "co", "Colocation Daily Mean CO by \nMonitor over Time")

plot_co_com_time <- plot_daily_mean_pollutant(co_community_daily, "co", "Community Daily Mean CO by \nMonitor over Time")

plot_no_col_time <- plot_daily_mean_pollutant(no_colocation_daily, "no", "Colocation Daily Mean NO by \nMonitor over Time")

plot_no_com_time <- plot_daily_mean_pollutant(no_community_daily, "no", "Community Daily Mean NO by \nMonitor over Time")

plot_no2_col_time <- plot_daily_mean_pollutant(no2_colocation_daily, "no2", "Colocation Daily Mean NO2 by \nMonitor over Time")

plot_no2_com_time <- plot_daily_mean_pollutant(no2_community_daily, "no2", "Community Daily Mean NO2 by \nMonitor over Time")

plot_o3_col_time <- plot_daily_mean_pollutant(o3_colocation_daily, "o3", "Colocation Daily Mean O3 by \nMonitor over Time")

plot_o3_com_time <- plot_daily_mean_pollutant(o3_community_daily, "o3", "Community Daily Mean O3 by \nMonitor over Time")
```

```{r, fig.height=8, fig.width=8, echo=FALSE, message=FALSE, warning=FALSE}
grid.arrange(plot_co_col_time, plot_no_col_time, plot_no2_col_time, plot_o3_col_time)

grid.arrange(plot_co_com_time, plot_no_com_time, plot_no2_com_time, plot_o3_com_time)
```

## Data Quality Check: Comparing Monitors to Golden Monitor

### CO Monitor Performance During Colocation 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# CO Colocation 
co_col_hour_plot <- compare_pollutant_to_reference(co_colocation_hourly, "MOD-00397", "co", "hourly", "Comparing Hourly CO to Monitor 00397 Readings: Colocation")

co_col_day_plot <- compare_pollutant_to_reference(co_colocation_daily, "MOD-00397", "co", "daily", "Comparing Daily CO to Monitor 00397 Readings: Colocation")

# CO Plots
grid.arrange(co_col_hour_plot, co_col_day_plot)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Combining everything for CO data with colocation, hourly
pollutant <- "co"
reference_monitor <- "MOD-00397"


time_frame <- "hourly"

# Step 1: Generate reference data
reference_data <- generate_reference_data(co_colocation_hourly, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
co_colocation_hourly_full <- join_reference_data(co_colocation_hourly, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(co_colocation_hourly_full, "mean_co", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for CO Colocation Hourly Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))




time_frame <- "daily"

# Step 1: Generate reference data
reference_data <- generate_reference_data(co_colocation_daily, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
co_colocation_daily_full <- join_reference_data(co_colocation_daily, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(co_colocation_daily_full, "mean_co", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for CO Colocation Daily Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

### CO Monitor Performance During Community Deployment  

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# CO community 
co_com_hour_plot <- compare_pollutant_to_reference(co_community_hourly, "MOD-00397", "co", "hourly", "Comparing Daily CO to Monitor 00397 Readings: Community Deployment")

co_com_day_plot <- compare_pollutant_to_reference(co_community_daily, "MOD-00397", "co", "daily", "Comparing Daily CO to Monitor 00397 Readings: Community Deployment")

grid.arrange(co_com_hour_plot, co_com_day_plot)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Combining everything for CO data with community, hourly
pollutant <- "co"
reference_monitor <- "MOD-00397"


time_frame <- "hourly"

# Step 1: Generate reference data
reference_data <- generate_reference_data(co_community_hourly, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
co_community_hourly_full <- join_reference_data(co_community_hourly, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(co_community_hourly_full, "mean_co", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for CO Community Hourly Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))


time_frame <- "daily"

# Step 1: Generate reference data
reference_data <- generate_reference_data(co_community_daily, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
co_community_daily_full <- join_reference_data(co_community_daily, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(co_community_daily_full, "mean_co", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for CO Community Daily Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


### NO Monitor Performance During Colocation

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# NO Colocation 
no_col_hour_plot <- compare_pollutant_to_reference(no_colocation_hourly, "MOD-00397", "no", "hourly", "Comparing Hourly NO to Monitor 00397 Readings: Colocation")

no_col_day_plot <- compare_pollutant_to_reference(no_colocation_daily, "MOD-00397", "no", "daily", "Comparing Daily NO to Monitor 00397 Readings: Colocation")

# NO Plots
grid.arrange(no_col_hour_plot, no_col_day_plot)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Combining everything for NO data with colocation, hourly
pollutant <- "no"
reference_monitor <- "MOD-00397"


time_frame <- "hourly"

# Step 1: Generate reference data
reference_data <- generate_reference_data(no_colocation_hourly, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
no_colocation_hourly_full <- join_reference_data(no_colocation_hourly, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(no_colocation_hourly_full, "mean_no", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for NO Colocation Hourly Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))




time_frame <- "daily"

# Step 1: Generate reference data
reference_data <- generate_reference_data(no_colocation_daily, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
no_colocation_daily_full <- join_reference_data(no_colocation_daily, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(no_colocation_daily_full, "mean_no", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for NO Colocation Daily Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


### NO Monitor Performance During Community Deployment

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# NO community 
no_com_hour_plot <- compare_pollutant_to_reference(no_community_hourly, "MOD-00397", "no", "hourly", "Comparing Daily NO to Monitor 00397 Readings: Community Deployment")

no_com_day_plot <- compare_pollutant_to_reference(no_community_daily, "MOD-00397", "no", "daily", "Comparing Daily NO to Monitor 00397 Readings: Community Deployment")

grid.arrange(no_com_hour_plot, no_com_day_plot)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Combining everything for NO data with community, hourly
pollutant <- "no"
reference_monitor <- "MOD-00397"

time_frame <- "hourly"

# Step 1: Generate reference data
reference_data <- generate_reference_data(no_community_hourly, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
no_community_hourly_full <- join_reference_data(no_community_hourly, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(no_community_hourly_full, "mean_no", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for NO Community Hourly Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))


time_frame <- "daily"

# Step 1: Generate reference data
reference_data <- generate_reference_data(no_community_daily, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
no_community_daily_full <- join_reference_data(no_community_daily, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(no_community_daily_full, "mean_no", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for NO Community Daily Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


### $NO_2$ Monitor Performance During Colocation

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# NO2 Colocation
no2_col_hour_plot <- compare_pollutant_to_reference(no2_colocation_hourly, "MOD-00397", "no2", "hourly", bquote("Comparing Hourly NO"[2]*" to Monitor 00397 Readings: Colocation"))

no2_col_day_plot <- compare_pollutant_to_reference(no2_colocation_daily, "MOD-00397", "no2", "daily", bquote("Comparing Daily NO"[2]*" to Monitor 00397 Readings During: Colocation"))

# NO2 Plots
grid.arrange(no2_col_hour_plot, no2_col_day_plot)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Combining everything for NO2 data with colocation, hourly
pollutant <- "no2"
reference_monitor <- "MOD-00397"


time_frame <- "hourly"

# Step 1: Generate reference data
reference_data <- generate_reference_data(no2_colocation_hourly, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
no2_colocation_hourly_full <- join_reference_data(no2_colocation_hourly, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(no2_colocation_hourly_full, "mean_no2", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for NO2 Colocation Hourly Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))




time_frame <- "daily"

# Step 1: Generate reference data
reference_data <- generate_reference_data(no2_colocation_daily, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
no2_colocation_daily_full <- join_reference_data(no2_colocation_daily, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(no2_colocation_daily_full, "mean_no2", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for NO2 Colocation Daily Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


### $NO_2$ Monitor Performance During Community Deployment 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# NO2 Community
no2_com_hour_plot <- compare_pollutant_to_reference(no2_community_hourly, "MOD-00397", "no2", "hourly", bquote("Comparing Hourly NO"[2]*" to Monitor 00397 Readings: Community Deployment"))

no2_com_day_plot <- compare_pollutant_to_reference(no2_community_daily, "MOD-00397", "no2", "daily", bquote("Comparing Daily NO"[2]*" to Monitor 00397 Readings: Community Deployment"))

grid.arrange(no2_com_hour_plot, no2_com_day_plot)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Combining everything for NO2 data with community, hourly
pollutant <- "no2"
reference_monitor <- "MOD-00397"

time_frame <- "hourly"

# Step 1: Generate reference data
reference_data <- generate_reference_data(no2_community_hourly, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
no2_community_hourly_full <- join_reference_data(no2_community_hourly, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(no2_community_hourly_full, "mean_no2", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for NO2 Community Hourly Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))


time_frame <- "daily"

# Step 1: Generate reference data
reference_data <- generate_reference_data(no2_community_daily, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
no2_community_daily_full <- join_reference_data(no2_community_daily, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(no2_community_daily_full, "mean_no2", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for NO2 Community Daily Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


### $O_3$ Monitor Performance During Colocation 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# O3 colocation
o3_col_hour_plot <- compare_pollutant_to_reference(o3_colocation_hourly, "MOD-00397", "o3", "hourly", expression("Comparing Hourly O"[3] * " to Monitor 00397 Readings: Colocation"))

o3_col_day_plot <- compare_pollutant_to_reference(o3_colocation_daily, "MOD-00397", "o3", "daily", expression("Comparing Daily O"[3] * " to Monitor 00397 Readings: Colocation"))


# O3 Plots
grid.arrange(o3_col_hour_plot, o3_col_day_plot)
```



```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Combining everything for O3 data with colocation, hourly
pollutant <- "o3"
reference_monitor <- "MOD-00397"


time_frame <- "hourly"

# Step 1: Generate reference data
reference_data <- generate_reference_data(o3_colocation_hourly, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
o3_colocation_hourly_full <- join_reference_data(o3_colocation_hourly, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(o3_colocation_hourly_full, "mean_o3", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for O3 Colocation Hourly Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))




time_frame <- "daily"

# Step 1: Generate reference data
reference_data <- generate_reference_data(o3_colocation_daily, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
o3_colocation_daily_full <- join_reference_data(o3_colocation_daily, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(o3_colocation_daily_full, "mean_o3", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for O3 Colocation Daily Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

### $O_3$ Monitor Performance During Community Deployment

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# O3 community
o3_com_hour_plot <- compare_pollutant_to_reference(o3_community_hourly, "MOD-00397", "o3", "hourly", expression("Comparing Hourly O"[3] * " to Monitor 00397 Readings: Community Deployment"))

o3_com_day_plot <- compare_pollutant_to_reference(o3_community_daily, "MOD-00397", "o3", "daily", expression("Comparing Daily O"[3] * " to Monitor 00397 Readings: Community Deployment"))

grid.arrange(o3_com_hour_plot, o3_com_day_plot)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Combining everything for O3 data with community, hourly
pollutant <- "o3"
reference_monitor <- "MOD-00397"

time_frame <- "hourly"

# Step 1: Generate reference data
reference_data <- generate_reference_data(o3_community_hourly, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
o3_community_hourly_full <- join_reference_data(o3_community_hourly, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(o3_community_hourly_full, "mean_o3", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for O3 Community Hourly Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))


time_frame <- "daily"

# Step 1: Generate reference data
reference_data <- generate_reference_data(o3_community_daily, reference_monitor, pollutant, time_frame)

# Step 2: Join reference data with the full dataset
o3_community_daily_full <- join_reference_data(o3_community_daily, reference_data, time_frame)

# Step 3: Apply regression
regression_results <- apply_regression_gas(o3_community_daily_full, "mean_o3", "monitor_MOD-00397")

# Display the results
kable(regression_results, caption = "Regression Results for O3 Community Daily Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```



## Gas Trends: Heatmaps 
```{r, echo=FALSE, message=FALSE, warning=FALSE}
generate_heatmap(co_colocation_hourly, "co")

generate_heatmap(co_community_hourly, "co")

generate_heatmap(no_colocation_hourly, "no")

generate_heatmap(no_community_hourly, "no")

generate_heatmap(no2_colocation_hourly, "no2")

generate_heatmap(no2_community_hourly, "no2")

generate_heatmap(o3_colocation_hourly, "o3")

generate_heatmap(o3_community_hourly, "o3")
```






