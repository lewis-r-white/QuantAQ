---
title: "Pollutant (PM + Gas) Data Prep"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen=999)
```

This R Markdown document reads in processed SD card, merges it with cloud data, and applies correction formula based on co-location regression.
 
It starts by cleaning particulate matter (PM) data, and then follows with gas data. 

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
### load packages 

library(here) # file path org
library(lubridate)# working with dates
library(tictoc) # timing
library(DT) # datatables
library(purrr) # applying functions across df
library(tidyverse) # data cleaning and plotting
library(data.table) 
library(sf) # spatial data 
library(viridis) # color pallete 
library(knitr)
library(modelsummary) # table of regressions
library(spdep)
library(gstat)
library(units) 
library(gridExtra)
library(broom)
library(Metrics) 
library(kableExtra) # table creation
library(GGally)


# source in function that loads each pollution dataset separately to keep data small and prevent R crashes 
source(here("src", "load_pollution_datasets.R"))

# source function that aggregates data by time scale of interest (hourly, daily)
source(here("src", "summarize_pollution_times.R"))


# source function to apply regressions when comparing monitor to fleet average
source(here("src", "compare_fleet_regression.R")) # INCLUDES apply_regression and run_regression_stats functions. 

# source functions to merge in the SD card data for cases when server data is missing 
source(here("src", "merge_sd_data.R"))
source(here("src", "process_multiple_pollutants.R"))

source(here("src", "merge_cloud_sd_colocation_and_community.R"))
```


# Pollutants 

### load the data

```{r}
## LOAD SD CARD DATA ----

# List all MOD files with full path
mod_files <- list.files(
  path = "/Users/lewiswhite/CHAP_columbia/QuantAQ/data/all_measurements/sd/processed_oct_2024/MOD", 
  full.names = TRUE, 
  recursive = FALSE, 
  pattern = "MOD-00.*\\.csv"
)

# List all MOD-PM files with full path
mod_pm_files <- list.files(
  path = "/Users/lewiswhite/CHAP_columbia/QuantAQ/data/all_measurements/sd/processed_oct_2024/MOD-PM", 
  full.names = TRUE, 
  recursive = FALSE, 
  pattern = "MOD-PM.*\\.csv"
)

# Function to read, select columns, and add monitor name for MOD files
read_and_select_mod <- function(file) {
  # Extract the monitor name from the file name
  monitor_name <- str_extract(basename(file), "MOD-\\d+")
  
  read_csv(file) %>%
    select(timestamp_iso, co:pm25) %>%
    mutate(monitor = monitor_name)
}


# Function to read, select columns, and add monitor name for MOD-PM files
read_and_select_mod_pm <- function(file) {
  # Extract the monitor name from the file name
  monitor_name <- str_extract(basename(file), "MOD-PM-\\d+")
  
  read_csv(file) %>%
    select(timestamp_iso, pm1:pm25) %>%
    mutate(monitor = monitor_name)
}

# Read all MOD files and combine them
MOD_sd_card <- mod_files %>%
  map_dfr(read_and_select_mod)

# Read all MOD-PM files and combine them
MOD_PM_sd_card <- mod_pm_files %>%
  map_dfr(read_and_select_mod_pm)


full_sd_card = bind_rows(MOD_sd_card, MOD_PM_sd_card) %>%
  filter(pm10 < 5000) 


# write_csv(full_sd_card, here("data", "all_measurements", "sd", "full_sd_card_2023-04-24_to_2024-09-11.csv")) 

full_sd_card <- read_csv(here("data", "all_measurements", "sd", "full_sd_card_2023-04-24_to_2024-09-11.csv")) %>%
 mutate(source = "sd_card")



# LOAD CLOUD DATA ---- 

# List of pollutants
pollutants <- c("pm1", "pm25", "pm10")

file_path <- "/Users/lewiswhite/CHAP_columbia/QuantAQ/data/all_measurements/cloud/ghana_AQ_parent_full_20230815-20240925.csv"

# Load all cloud data in a structured way
raw_data <- lapply(pollutants, function(pollutant) {
  load_pollution_datasets(pollutant, file_path = file_path, file_type = "csv")
})

# Name the list by pollutant
names(raw_data) <- pollutants

```


### Merge the cloud and SD data

```{r}
## MERGE THE SD DATA WITH THE SERVER DATA ---- 
merged_results <- merge_cloud_sd_colocation_and_community(pollutants, raw_data, full_sd_card)
```


### Determine correction equation

```{r}
## PM 1 ---- 
# use just the colocation data for correction equation 
pm1_colocation_merged <- merged_results$pm1$merged_colocation

# filter to observations that exist with at least 10 other monitors at same time for fleet average
pm1_regression_data <- pm1_colocation_merged %>% 
  group_by(timestamp) %>% 
  summarize(offline_monitors = sum(is.na(pm1))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm1_colocation_merged) %>%
  
  filter(offline_monitors < 30) %>% # only use fleet average data for correction when at least 10 monitors are active 
  
  filter(!is.na(pm1))  # remove NAs

# calculate the fleet average for each minute of available data
fleet_average_data <- pm1_regression_data %>%
  group_by(timestamp) %>%
  summarise(fleet_average_pm1 = mean(pm1))

# add the fleet average data to the regression data 
pm1_regression_data <- left_join(pm1_regression_data, fleet_average_data)  

# apply the regression to get the slope, intercept, rmse etc. 
pm1_colocation_regression_results <- apply_regression(pm1_regression_data, "pm1", "fleet_average_pm1") # apply_regression is in file compare_fleet_regression.R



## PM 2.5 ----
pm25_colocation_merged <- merged_results$pm25$merged_colocation

# filter to observations that exist with at least 10 other monitors at same time for fleet average
pm25_regression_data <- pm25_colocation_merged %>% 
  group_by(timestamp) %>% 
  summarize(offline_monitors = sum(is.na(pm25))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm25_colocation_merged) %>%
  
  filter(offline_monitors < 30) %>%
  
  filter(!is.na(pm25)) 

fleet_average_data <- pm25_regression_data %>%
  group_by(timestamp) %>%
  summarise(fleet_average_pm25 = mean(pm25))

pm25_regression_data <- left_join(pm25_regression_data, fleet_average_data)  


## PLOTTING pm25 regression data for report appendix

# remove outliers to better show regression results for report 
pm25_reg_data_no_outliers <- pm25_regression_data %>% filter(pm25 < 250, fleet_average_pm25 < 250)

ggplot(pm25_reg_data_no_outliers, aes(x = fleet_average_pm25, y = pm25)) +
    geom_point(alpha = 0.1) +
    facet_wrap(~monitor, ncol = 5) +
    theme_bw() +
    labs(x = "Fleet Average PM 2.5",
         y = "Monitor PM 2.5") +
    scale_x_continuous(breaks = c(0, 100, 200)) +  # Set x-axis ticks
    scale_y_continuous(breaks = c(0, 100, 200)) +  # Set y-axis ticks
    theme(
      axis.title = element_text(size = 14),   # Increase axis titles size
      axis.text = element_text(size = 11),    # Increase axis labels size
      strip.text = element_text(size = 12)    # Increase facet group text size
    )


# CREATE SUMMARY TABLE OF REGRESSION RESULTS 
pm25_colocation_regression_results <- apply_regression(pm25_regression_data, "pm25", "fleet_average_pm25") # apply regression in compare_fleet_regression.R

pdf_table <- pm25_colocation_regression_results %>%
  kbl(caption = "PM2.5 Colocation Regression Results",
      col.names = c("Monitor", "N", "Slope", "Intercept", "RMSE", "AME"),
      format = "html", 
      align = c("l", "r", "r", "r", "r", "r")) %>%
  kable_classic(full_width = F, html_font = "Times New Roman") %>%
  add_header_above(c(" " = 2, "Regression Parameters" = 2, "Error Metrics" = 2)) %>%
  column_spec(1, bold = T) %>%
  row_spec(0, bold = T) %>%
  footnote(general = "N = number of observations, RMSE = Root Mean Square Error, AME = Absolute Mean Error")

# save_kable(pdf_table, file = "pm25_colocation_regression_results.pdf")




## PM 10 ----
pm10_colocation_merged <- merged_results$pm10$merged_colocation

pm10_regression_data <- pm10_colocation_merged %>% 
  group_by(timestamp) %>% 
  summarize(offline_monitors = sum(is.na(pm10))) %>%
  ungroup() %>%
  
  #add the PM data back
  left_join(pm10_colocation_merged) %>%
  
  filter(offline_monitors < 30) %>%
  
  filter(!is.na(pm10)) 

fleet_average_data <- pm10_regression_data %>%
  group_by(timestamp) %>%
  summarise(fleet_average_pm10 = mean(pm10))

pm10_regression_data <- left_join(pm10_regression_data, fleet_average_data)  

pm10_colocation_regression_results <- apply_regression(pm10_regression_data, "pm10", "fleet_average_pm10") # apply regression in compare_fleet_regression.R





# ## Save colocation data ----
# write_rds(pm1_colocation_merged, here("data", "pm","colocation", "pm1_colocation_merged.rds"))
# write_rds(pm25_colocation_merged, here("data", "pm","colocation", "pm25_colocation_merged.rds"))
# write_rds(pm10_colocation_merged, here("data", "pm","colocation", "pm10_colocation_merged.rds"))
```


### Apply correction equation 

```{r}
# PM 1 ----
pm1_community_merged <- merged_results$pm1$merged_community

pm1_corrected <- pm1_community_merged %>%
  left_join(pm1_colocation_regression_results, by = "monitor") %>%
  mutate(corrected_pm1 = (pm1 - intercept) / slope) %>%
  select(monitor, timestamp, date, hour, corrected_pm1, source) %>%
  rename(pm1 = corrected_pm1)

# write_rds(pm1_corrected, here("data", "pm1corrected.rds"))


# PM 2.5 ----

pm25_community_merged <- merged_results$pm25$merged_community

pm25_corrected <- pm25_community_merged %>%
  left_join(pm25_colocation_regression_results, by = "monitor") %>%
  mutate(corrected_pm25 = (pm25 - intercept) / slope) %>%
  select(monitor, timestamp, date, hour, corrected_pm25, source) %>%
  rename(pm25 = corrected_pm25)

# write_rds(pm25_corrected, here("data", "pm25corrected.rds"))


# PM 10 ----
pm10_community_merged <- merged_results$pm10$merged_community

pm10_corrected <- pm10_community_merged %>%
  left_join(pm10_colocation_regression_results, by = "monitor") %>%
  mutate(corrected_pm10 = (pm10 - intercept) / slope) %>%
  select(monitor, timestamp, date, hour, corrected_pm10, source) %>%
  rename(pm10 = corrected_pm10)

# write_rds(pm10_corrected, here("data", "pm10corrected.rds"))
```


### summarize the data based on corrected values

```{r}
summarized_pm1 <- summarize_pollution_times(pm1_corrected, "pm1")
summarized_pm25 <- summarize_pollution_times(pm25_corrected, "pm25")
summarized_pm10 <- summarize_pollution_times(pm10_corrected, "pm10")

pm1_community_hourly <- summarized_pm1$hourly
pm1_community_daily <- summarized_pm1$daily

pm25_community_hourly <- summarized_pm25$hourly
pm25_community_daily <- summarized_pm25$daily

pm10_community_hourly <- summarized_pm10$hourly
pm10_community_daily <- summarized_pm10$daily
```


### Save the output 

```{r}
# # Save as CSV
# write_csv(pm1_community_hourly, here("data", "pm", "summarized", "pm1_community_hourly_20231024-20240816.csv"))
# write_csv(pm25_community_hourly, here("data", "pm", "summarized", "pm25_community_hourly_20231024-20240816.csv"))
# write_csv(pm10_community_hourly, here("data", "pm", "summarized", "pm10_community_hourly_20231024-20240816.csv"))
# 
# write_csv(pm1_community_daily, here("data", "pm", "summarized", "pm1_community_daily_20231024-20240816.csv"))
# write_csv(pm25_community_daily, here("data", "pm", "summarized", "pm25_community_daily_20231024-20240816.csv"))
# write_csv(pm10_community_daily, here("data", "pm", "summarized", "pm10_community_daily_20231024-20240816.csv"))
# 
# 
# # Save as RDS 
# write_rds(pm1_community_hourly, here("data", "pm", "summarized", "pm1_community_hourly_20231024-20240816.rds"))
# write_rds(pm25_community_hourly, here("data", "pm", "summarized", "pm25_community_hourly_20231024-20240816.rds"))
# write_rds(pm10_community_hourly, here("data", "pm", "summarized", "pm10_community_hourly_20231024-20240816.rds"))
# 
# write_rds(pm1_community_daily, here("data", "pm", "summarized", "pm1_community_daily_20231024-20240816.rds"))
# write_rds(pm25_community_daily, here("data", "pm", "summarized", "pm25_community_daily_20231024-20240816.rds"))
# write_rds(pm10_community_daily, here("data", "pm", "summarized", "pm10_community_daily_20231024-20240816.rds"))

```


# Gases

### load in the data

```{r}
# LOAD SD CARD DATA ----

# List all MOD files with full path
mod_files <- list.files(
  path = "/Users/lewiswhite/CHAP_columbia/QuantAQ/data/all_measurements/sd/processed_oct_2024/MOD", 
  full.names = TRUE, 
  recursive = FALSE, 
  pattern = "MOD-00.*\\.csv"
)

# Function to read, select columns, and add monitor name for MOD files
read_and_select_mod <- function(file) {
  # Extract the monitor name from the file name
  monitor_name <- str_extract(basename(file), "MOD-\\d+")
  
  read_csv(file) %>%
    select(timestamp_iso, co:pm25) %>%
    mutate(monitor = monitor_name)
}

# Read all MOD files and combine them
MOD_sd_card <- mod_files %>%
  map_dfr(read_and_select_mod)

# MOD data loaded above, so just select gases
MOD_gas_sd_card <- MOD_sd_card %>% select(-(pm1:pm25)) %>% mutate(source = "sd_card")

# save output
# write_rds(MOD_gas_sd_card, here("data", "gas", "raw", "gas_sd_card_20230423-20240905.rds"))

# read in gas sd card data if no new SD card data 
MOD_gas_sd_card <- read_rds(here("data", "gas","raw", "gas_sd_card_20230423-20240905.rds"))




# LOAD CLOUD DATA ----

pollutants <- c("co", "no", "no2", "o3")

cloud_file_path <- "/Users/lewiswhite/CHAP_columbia/QuantAQ/data/all_measurements/cloud/ghana_AQ_parent_full_20230815-20240925.csv"

raw_data <- lapply(pollutants, function(pollutant) {
  full_data <- load_pollution_datasets(pollutant, file_path = cloud_file_path, file_type = "csv")

  # Filter out MOD-PM (keep only MOD devices with gases)
  full_data <- lapply(full_data, function(df) {
    df %>% filter(str_detect(monitor, "^MOD-[^P]"))
  })

  return(full_data)
})

names(raw_data) <- pollutants

```


### Merge the cloud and SD data

```{r}
# merge cloud and SD 
gas_merged_results <- merge_cloud_sd_colocation_and_community(pollutants, raw_data, MOD_gas_sd_card)



# Extract & deduplicate merged_full
co_merged <- gas_merged_results$co$merged_full %>% distinct(monitor, timestamp, .keep_all = TRUE)
no_merged <- gas_merged_results$no$merged_full %>% distinct(monitor, timestamp, .keep_all = TRUE)
no2_merged <- gas_merged_results$no2$merged_full %>% distinct(monitor, timestamp, .keep_all = TRUE)
o3_merged <- gas_merged_results$o3$merged_full %>% distinct(monitor, timestamp, .keep_all = TRUE)

# Combine into one table
gas_full <- full_join(co_merged, no_merged) %>%
  full_join(no2_merged) %>%
  full_join(o3_merged) %>%
  select(monitor, timestamp, date, hour, co, no, no2, o3, source) %>%
  mutate(source = ifelse(rowSums(across(c(co, no, no2, o3), ~ !is.na(.))) == 0, NA, source))

```


### Plot gas time series and examine correlations to determine "golden monitor" to be used for colocation correction

```{r}
## COLOCATION DATA TIME SERIES ----

colocation_gas <- gas_full %>% 
  filter(date < as.Date("2023-10-26")) 

write_rds(colocation_gas, here("data", "gas", "colocation", "colocation_gas.rds"))


colocation_gas %>% 
  filter(date < as.Date("2023-10-26")) %>%
  group_by(monitor, date) %>%
  summarise(
    mean_co = mean(co, na.rm = TRUE),
    mean_no2 = mean(no2, na.rm = TRUE),
    mean_o3 = mean(o3, na.rm = TRUE),
    mean_no = mean(no, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_longer(cols = starts_with("mean_"), names_to = "gas", values_to = "mean_concentration") %>%
  mutate(gas = gsub("mean_", "", gas)) %>%
  ggplot(aes(x = date, y = mean_concentration, color = gas)) +
  geom_line() +
  facet_grid(gas ~ monitor, scales = "free_y") +  # Facet by gas and then monitor
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(y = "Mean Concentration", x = "Date", color = "Gas", title = "Daily Average Time Series for Each Gas/Monitor")



## COMMUNITY DATA TIME SERIES ----

gas_full %>% filter(date > as.Date("2023-10-26")) %>%
  group_by(monitor, date) %>%
  summarise(
    mean_co = mean(co, na.rm = TRUE),
    mean_no2 = mean(no2, na.rm = TRUE),
    mean_o3 = mean(o3, na.rm = TRUE),
    mean_no = mean(no, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_longer(cols = starts_with("mean_"), names_to = "gas", values_to = "mean_concentration") %>%
  mutate(gas = gsub("mean_", "", gas)) %>%
  ggplot(aes(x = date, y = mean_concentration, color = gas)) +
  geom_line() +
  facet_grid(gas ~ monitor, scales = "free_y") +  # Facet by gas and then monitor
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(y = "Mean Concentration", x = "Date", color = "Gas")
  


### LOOKING AT CORRELATIONS BETWEEN MONITORS -----

# NO SUMMARIZED 
summarized_no <- summarize_pollution_times(colocation_gas, "no")
no_hourly <- summarized_no$hourly

# NO NON FILTER 
# Transform data: Spread 'no' values into wide format by monitor
no_colocation_wide <- no_hourly %>%
  spread(key = monitor, value = mean_no)

# Generate pairwise correlation plot
ggpairs(no_colocation_wide %>% select(`MOD-00397`:`MOD-00401`), 
        upper = list(continuous = wrap("cor", method = "pearson")), 
        lower = list(continuous = wrap("smooth", method = "lm", se = TRUE, color = "blue", alpha = 0.5)),
        diag = list(continuous = "densityDiag")) +  
  theme_minimal() + 
  labs(title = "Pairwise Correlation of Hourly NO Values with Regression Slopes")



# NO WITH FILTER 
no_hourly_filtered <- no_hourly %>% filter(date > as.Date("2023-08-22"))

# Transform data: Spread 'no' values into wide format by monitor
no_colocation_wide <- no_hourly_filtered %>%
  spread(key = monitor, value = mean_no)

ggpairs(no_colocation_wide %>% select(`MOD-00397`:`MOD-00401`), 
        upper = list(continuous = wrap("cor", method = "pearson")), 
        lower = list(continuous = wrap("smooth", method = "lm", se = TRUE, color = "blue", alpha = 0.5)),
        diag = list(continuous = "densityDiag")) +  
  theme_minimal() + 
  labs(title = "Pairwise Correlation of Hourly NO Values", 
       subtitle = "Filtered to after Aug 21 to remove outliers") 
  



# NO2 SUMMARIZED 
summarized_no2 <- summarize_pollution_times(colocation_gas, "no2")
no2_hourly <- summarized_no2$hourly

# NO2 PLOT
# Transform data: Spread 'no2' values into wide format by monitor
no2_colocation_wide <- no2_hourly %>%
  spread(key = monitor, value = mean_no2)

# Generate pairwise correlation plot
ggpairs(no2_colocation_wide %>% select(`MOD-00397`:`MOD-00400`), 
        upper = list(continuous = wrap("cor", method = "pearson")), # Show correlation
        lower = list(continuous = wrap("smooth", method = "lm", se = TRUE, color = "blue", alpha = 0.5)),
        diag = list(continuous = "densityDiag")) +  
  theme_minimal() + 
  labs(title = "Pairwise Correlation of Hourly NO2 Values")




# CO SUMMARIZED 
summarized_co <- summarize_pollution_times(colocation_gas, "co")
co_hourly <- summarized_co$hourly

# CO PLOT
# Transform data: Spread 'co' values into wide format by monitor
co_colocation_wide <- co_hourly %>%
  spread(key = monitor, value = mean_co)

# Generate pairwise correlation plot
ggpairs(co_colocation_wide %>% select(`MOD-00397`:`MOD-00401`), 
        upper = list(continuous = wrap("cor", method = "pearson")), # Show correlation
        lower = list(continuous = wrap("smooth", method = "lm", se = TRUE, color = "blue", alpha = 0.5)),
        diag = list(continuous = "densityDiag")) +  
  theme_minimal() + 
  labs(title = "Pairwise Correlation of Hourly CO Values")



# O3 SUMMARIZED 
summarized_o3 <- summarize_pollution_times(colocation_gas, "o3")
o3_hourly <- summarized_o3$hourly

# O3 PLOT
# Transform data: Spread 'o3' values into wide format by monitor
o3_colocation_wide <- o3_hourly %>%
  spread(key = monitor, value = mean_o3)

# Generate pairwise correlation plot
ggpairs(o3_colocation_wide %>% select(`MOD-00397`:`MOD-00401`), 
        upper = list(continuous = wrap("cor", method = "pearson")), # Show correlation
        lower = list(continuous = wrap("smooth", method = "lm", se = TRUE, color = "blue", alpha = 0.5)),
        diag = list(continuous = "densityDiag")) +  
  theme_minimal() + 
  labs(title = "Pairwise Correlation of Hourly O3 Values")



### REGRESSION WITH SLOPE PLOTS ----
library(ggpubr)

# Select only monitor columns
monitor_cols <- o3_colocation_wide %>% select(`MOD-00397`:`MOD-00401`)

# Get all unique pairs of monitor columns (including self-pairs for a full 5x5 grid)
monitor_pairs <- expand.grid(monitor_x = names(monitor_cols), monitor_y = names(monitor_cols), 
                             stringsAsFactors = FALSE)

# Function to generate scatterplot with regression line and annotation
plot_regression <- function(x, y) {
  df <- no_colocation_wide %>% select(all_of(c(x, y))) %>% drop_na()
  
  # Compute correlation and regression slope
  cor_val <- round(cor(df[[x]], df[[y]], use = "complete.obs"), 3)
  model <- lm(df[[y]] ~ df[[x]], data = df)
  slope_val <- round(coef(model)[2], 3)
  
  ggplot(df, aes(x = .data[[x]], y = .data[[y]])) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "blue") +
    labs(title = paste(x, "vs", y),
         subtitle = paste("Corr:", cor_val, "\nSlope:", slope_val),
         x = x, y = y) +
    theme_minimal()
}

# Generate a list of plots for each pair of monitors
plot_list <- map2(monitor_pairs$monitor_x, monitor_pairs$monitor_y, plot_regression)

# Arrange the plots into a grid using ggarrange
ggarrange(plotlist = plot_list, ncol = 5, nrow = 5)
```


### Pull data from golden monitor 

```{r}
get_reference_data <- function(colocation_data, monitor_id, gases) {
  ref_cols <- setNames(gases, paste0("reference_", gases))
  
  colocation_data %>%
    filter(monitor == monitor_id) %>%
    select(timestamp, !!!setNames(syms(gases), names(ref_cols)))
}


gases <- c("co", "no", "no2", "o3")

reference_data <- get_reference_data(colocation_gas, "MOD-00397", gases)

colocation_with_ref <- left_join(colocation_gas, reference_data, by = "timestamp")
```



### Determine the correction equation

```{r}
get_gas_regression_results <- function(colocation_with_ref, gases, reference_gases) {
  results_list <- list()
  
  for (monitor in unique(colocation_with_ref$monitor)) {
    monitor_data <- colocation_with_ref %>% filter(monitor == !!monitor)
    
    for (i in seq_along(gases)) {
      gas <- gases[i]
      reference_gas <- reference_gases[i]
      
      valid_data <- monitor_data %>% filter(!is.na(.data[[gas]]), !is.na(.data[[reference_gas]]))
      
      if (nrow(valid_data) >= 2) {
        model <- lm(as.formula(paste(gas, "~", reference_gas)), data = valid_data)
        results_list[[length(results_list) + 1]] <- tibble(
          monitor = monitor,
          gas = gas,
          slope = coef(model)[[2]],
          intercept = coef(model)[[1]],
          R2 = summary(model)$r.squared
        )
      } else {
        results_list[[length(results_list) + 1]] <- tibble(
          monitor = monitor, gas = gas, slope = NA, intercept = NA, R2 = NA
        )
      }
    }
  }
  
  bind_rows(results_list)
}


# apply regression function
regression_results <- get_gas_regression_results(colocation_with_ref, gases, paste0("reference_", gases))

```


### Apply the correction equation 

```{r}
apply_gas_correction <- function(community_gas, regression_table, gases) {
  # Reshape regression table
  reformat <- regression_table %>%
    select(monitor, gas, slope, intercept) %>%
    pivot_longer(c(slope, intercept), names_to = "param", values_to = "value") %>%
    mutate(param = paste(gas, param, sep = "_")) %>%
    select(-gas) %>%
    pivot_wider(names_from = param, values_from = value)
  
  # Join and correct
  community_gas %>%
    left_join(reformat, by = "monitor") %>%
    mutate(
      co  = (co - co_intercept) / co_slope,
      no  = (no - no_intercept) / no_slope,
      no2 = (no2 - no2_intercept) / no2_slope,
      o3  = (o3 - o3_intercept) / o3_slope
    ) %>%
    select(monitor, timestamp, date, hour, co, no, no2, o3, source)
}


# apply gas correction function 

corrected_community_gas <- apply_gas_correction(gas_full %>% filter(date >= as.Date("2023-09-26")), regression_results, gases)

# Save output 
#write_rds(corrected_community_gas, here("data", "gas", "final", "corrected_community_gas_20230926-20240816.rds"))
```


### summarize the data

```{r}
summarize_corrected_gases <- function(corrected_data, gases) {
  summaries <- list()
  for (gas in gases) {
    gas_df <- corrected_data %>%
      select(monitor, timestamp, date, hour, source, !!sym(gas))
    summaries[[gas]] <- summarize_pollution_times(gas_df, gas)
  }
  return(summaries)
}

summarized_gases <- summarize_corrected_gases(corrected_community_gas, gases)



co_community_hourly <- summarized_gases$co$hourly
no_community_hourly <- summarized_gases$no$hourly
no2_community_hourly <- summarized_gases$no2$hourly
o3_community_hourly <- summarized_gases$o3$hourly

co_community_daily <- summarized_gases$co$daily
no_community_daily <- summarized_gases$no$daily
no2_community_daily <- summarized_gases$no2$daily
o3_community_daily <- summarized_gases$o3$daily
```


### Save the output 

```{r}
# # Save as CSV
# write_csv(co_community_hourly, here("data", "gas", "summarized", "co_community_hourly_20231024-20240816.csv"))
# write_csv(no_community_hourly, here("data", "gas", "summarized", "no_community_hourly_20231024-20240816.csv"))
# write_csv(no2_community_hourly, here("data", "gas", "summarized", "no2_community_hourly_20231024-20240816.csv"))
# write_csv(o3_community_hourly, here("data", "gas", "summarized", "o3_community_hourly_20231024-20240816.csv"))
# 
# write_csv(co_community_daily, here("data", "gas", "summarized", "co_community_daily_20231024-20240816.csv"))
# write_csv(no_community_daily, here("data", "gas", "summarized", "no_community_daily_20231024-20240816.csv"))
# write_csv(no2_community_daily, here("data", "gas", "summarized", "no2_community_daily_20231024-20240816.csv"))
# write_csv(o3_community_daily, here("data", "gas", "summarized", "o3_community_daily_20231024-20240816.csv"))
# 
# # Save as RDS
# write_rds(co_community_hourly, here("data", "gas", "summarized", "co_community_hourly_20231024-20240816.rds"))
# write_rds(no_community_hourly, here("data", "gas", "summarized", "no_community_hourly_20231024-20240816.rds"))
# write_rds(no2_community_hourly, here("data", "gas", "summarized", "no2_community_hourly_20231024-20240816.rds"))
# write_rds(o3_community_hourly, here("data", "gas", "summarized", "o3_community_hourly_20231024-20240816.rds"))
# 
# write_rds(co_community_daily, here("data", "gas", "summarized", "co_community_daily_20231024-20240816.rds"))
# write_rds(no_community_daily, here("data", "gas", "summarized", "no_community_daily_20231024-20240816.rds"))
# write_rds(no2_community_daily, here("data", "gas", "summarized", "no2_community_daily_20231024-20240816.rds"))
# write_rds(o3_community_daily, here("data", "gas", "summarized", "o3_community_daily_20231024-20240816.rds"))
```



